{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext(conf=SparkConf().setAppName(\"MyApp\").setMaster(\"local[8]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_edge(s):\n",
    "    u, f = s.split(\"\\t\")\n",
    "    return (int(u), int(f))\n",
    "\n",
    "def step(i): \n",
    "    pv, pd, nv = i[0], i[1][0], i[1][1] \n",
    "    return (nv, pd + 1)\n",
    "\n",
    "def complete(item): \n",
    "    v, od, nd = item[0], item[1][0], item[1][1]\n",
    "    return (v, od if od is not None else nd)\n",
    "\n",
    "def update_path(x):\n",
    "    v, (old_path, (dist, new_v)) = x\n",
    "    return new_v, old_path + (new_v,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortest_path(v_from, v_to, dataset_path, numPartitions=10):\n",
    "    edges = sc.textFile(dataset_path, numPartitions).map(parse_edge).cache()\n",
    "    forward_edges = edges.map(lambda e: (e[1], e[0])).partitionBy(numPartitions).cache()\n",
    "    \n",
    "    d = 0\n",
    "    distances = sc.parallelize([(v_from, d)]).partitionBy(numPartitions)\n",
    "    paths = sc.parallelize([(v_from, (v_from,))])\n",
    "    \n",
    "    while True:\n",
    "        candidates = distances.join(forward_edges, numPartitions).map(step)\n",
    "        paths = paths.join(forward_edges).map(lambda x: (x[1][1], x[1][0] + (x[1][1],))).union(paths).distinct().cache()\n",
    "        new_distances = distances.fullOuterJoin(candidates).map(complete).distinct().cache()\n",
    "        count = new_distances.filter(lambda i: i[1] == d + 1).count()   \n",
    "        if count > 0:\n",
    "            d += 1     \n",
    "            distances = new_distances\n",
    "            # print \"d = {}, count = {}\".format(d, count)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    result = paths.filter(lambda x: x[1][0] == v_from and x[1][-1] == v_to).collect()\n",
    "    return ','.join(map(str, sorted(result, key=lambda x: len(x[1]))[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.58 s, sys: 1.83 s, total: 5.41 s\n",
      "Wall time: 11min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'12,422,53,52,107,20,23,274,34'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "shortest_path(12, 34, \"/data/twitter/twitter_sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
