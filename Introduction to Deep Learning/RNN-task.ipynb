{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print (x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZhlzCJiZZcwhYGaWMYeAmVnG/j9X9jq2BqwyjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9bc381f160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len,names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len,names)),bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need next to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "tokens = set(''.join(names))\n",
    "\n",
    "tokens = list(tokens)\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {symbol : index for symbol,index in zip(tokens,range(len(tokens)))}\n",
    "###YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names,max_len=None,pad=0,dtype='int32'):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,names))\n",
    "    names_ix = np.zeros([len(names),max_len],dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get,names[i]))\n",
    "        names_ix[i,:len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[52 13 14 36 11 36 15 53  0]\n",
      " [52 40 53 50 30 37  0  0  0]\n",
      " [52 51 30 48 32 32 48 15  0]\n",
      " [52 40 48 50 26 36  9  9 15]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=480>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Concatenate,Dense,Embedding\n",
    "\n",
    "rnn_num_units = 64\n",
    "embedding_size = 16\n",
    "\n",
    "#Let's create layers for our recurrent network\n",
    "#Note: we create layers but we don't \"apply\" them yet\n",
    "embed_x = Embedding(n_tokens,embedding_size) # an embedding layer that converts character ids into embeddings\n",
    "\n",
    "\n",
    "#a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units,activation=\"relu\")\n",
    "###YOUR CODE HERE\n",
    "\n",
    "#a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(len(tokens),activation=\"softmax\")\n",
    "\n",
    "#Note: please either set the correct activation to Dense or write it manually in rnn_one_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces next state and output\n",
    "    given prev input and previous state.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    Follow inline isntructions to complete the function.\n",
    "    \"\"\"\n",
    "    #convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t,[-1,1]))[:,0]\n",
    "    \n",
    "    #concatenate x embedding and previous h state\n",
    "   # x_and_h = Concatenate()([x_t_emb, h_t])\n",
    "    \n",
    "    x_and_h = tf.concat([x_t_emb, h_t], 1)\n",
    "\n",
    "    ###YOUR CODE HERE\n",
    "    \n",
    "    #compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    #get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas,h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop\n",
    "\n",
    "Once rnn_one_step is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder('int32',(MAX_LENGTH,None))\n",
    "batch_size = tf.shape(input_sequence)[1]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size,rnn_num_units]) #initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[t]\n",
    "    probas_next,h_next = rnn_one_step(x_t,h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "predicted_probas = tf.stack(predicted_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_matrix = tf.reshape(predicted_probas[:-1],[-1,len(tokens)])\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[1:],[-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.objectives import categorical_crossentropy\n",
    "\n",
    "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "s = keras.backend.get_session()\n",
    "s.run(tf.global_variables_initializer())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b6a5d4c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(10000):\n",
    "    batch = to_matrix(sample(names,32),max_len=MAX_LENGTH)\n",
    "    loss_i,_ = s.run([loss,optimize],{input_sequence:batch})\n",
    "    \n",
    "    \n",
    "    history.append(loss_i)\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = tf.placeholder('int32',(None,))\n",
    "h_t = tf.Variable(np.zeros([1,rnn_num_units],'float32'))\n",
    "\n",
    "next_probs,next_h = rnn_one_step(x_t,h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=' ',max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "        \n",
    "    parameters:\n",
    "        The phrase is set using the variable seed_phrase\n",
    "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t,h_t.initial_value))\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t,next_h),{x_t:[ix]})\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs,tf.assign(h_t,next_h)],{x_t:[x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens,p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kirby''''''''''\n",
      " Vemondy''''''''\n",
      " Gea''''''''''''\n",
      " Pugkie'''''''''\n",
      " Carieine'''''''\n",
      " Anton''''''''''\n",
      " Nyroll'''''''''\n",
      " Jana'''''''''''\n",
      " Lucelle''''''''\n",
      " Vavine'''''''''\n",
      " Joarolie'''''''\n",
      " Yoben''''''''''\n",
      " Tiffi''''''''''\n",
      " Gerro''''''''''\n",
      " Firot''''''''''\n",
      " Cachellina'''''\n",
      " Lerissa''''''''\n",
      " Doades'''''''''\n",
      " Gredr''''''''''\n",
      " Ruanerla'''''''\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Valon''''''''''\n",
      " Valias'''''''''\n",
      " Valey''''''''''\n",
      " Valvy''''''''''\n",
      " Valia''''''''''\n",
      " Valmene''''''''\n",
      " Valce''''''''''\n",
      " Valos''''''''''\n",
      " Valee''''''''''\n",
      " Valee''''''''''\n",
      " Valianna'''''''\n",
      " Valina'''''''''\n",
      " Valeera''''''''\n",
      " Valie''''''''''\n",
      " Vally''''''''''\n",
      " Valfra'''''''''\n",
      " Vallie'''''''''\n",
      " Valitae''''''''\n",
      " Valettia'''''''\n",
      " Valvon'''''''''\n",
      " Valwa''''''''''\n",
      " Valote'''''''''\n",
      " Vala'''''''''''\n",
      " Valiashe'''''''\n",
      " Valina'''''''''\n",
      " Valie''''''''''\n",
      " Valley'''''''''\n",
      " Valyn''''''''''\n",
      " Valdre'''''''''\n",
      " Valley'''''''''\n",
      " Valpo''''''''''\n",
      " Valie''''''''''\n",
      " Valema'''''''''\n",
      " Valypa'''''''''\n",
      " Vally''''''''''\n",
      " Valista''''''''\n",
      " Valci''''''''''\n",
      " Valee''''''''''\n",
      " Vallis'''''''''\n",
      " Valomand'''''''\n",
      " Valata'''''''''\n",
      " Valeah'''''''''\n",
      " Val''''''''''''\n",
      " Val''''''''''''\n",
      " Vallie'''''''''\n",
      " Valiance'''''''\n",
      " Valema'''''''''\n",
      " Vala'''''''''''\n",
      " Valmee'''''''''\n",
      " Val''''''''''''\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    print(generate_sample(' Val'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in range(25)]\n",
    "submission = (history,samples)\n",
    "submit_char_rnn(submission, 'VENHEADs@yandex.ru', 'qx7xEV2MHgJkWt0n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out!\n",
    "\n",
    "__Disclaimer:__ This assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* Ikea catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from keras, there's also a friendly tensorflow API for recurrent neural nets. It's based around the symbolic loop function (aka [scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10, 55)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self,input,state):\n",
    "        return rnn_one_step(input[:,0],state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "\n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder('int32',(None,None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell,input_sequence[:,:,None],\n",
    "                                                 time_major=True,dtype='float32')\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "with sess.as_default():\n",
    "    print(predicted_probas.eval({input_sequence:to_matrix(names[:10],max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use the all the pre-implemented RNN cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\n",
      "BasicRNNCell\n",
      "GRUCell\n",
      "LSTMCell\n",
      "MultiRNNCell\n",
      "RNNCell\n",
      "BasicLSTMCell\n",
      "BasicRNNCell\n",
      "BidirectionalGridLSTMCell\n",
      "CoupledInputForgetGateLSTMCell\n",
      "FusedRNNCell\n",
      "GLSTMCell\n",
      "GRUBlockCell\n",
      "GRUCell\n",
      "GridLSTMCell\n",
      "IntersectionRNNCell\n",
      "LSTMBlockCell\n",
      "LSTMBlockFusedCell\n",
      "LSTMCell\n",
      "LayerNormBasicLSTMCell\n",
      "MultiRNNCell\n",
      "NASCell\n",
      "PhasedLSTMCell\n",
      "RNNCell\n",
      "TimeFreqLSTMCell\n",
      "UGRNNCell\n"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell)+dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print (obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM visible states[time,batch,unit]: Tensor(\"rnn_2/transpose:0\", shape=(?, ?, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder('int32',(None,None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence,last_state = tf.nn.dynamic_rnn(cell,inputs_embedded,dtype='float32')\n",
    "\n",
    "print('LSTM visible states[time,batch,unit]:', state_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
