{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import cv2\n",
    "from segmentation_models import Unet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras import optimizers\n",
    "from os.path import join\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "from albumentations import (\n",
    "    CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, Blur, OpticalDistortion, \n",
    "    GridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, \n",
    "    MedianBlur, IAAPiecewiseAffine, IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, \n",
    "    Flip, OneOf, Compose,HorizontalFlip\n",
    ")\n",
    "from losses_original import (\n",
    "    binary_crossentropy,\n",
    "    dice_loss,\n",
    "    bce_dice_loss,\n",
    "    dice_coef,\n",
    "    weighted_bce_dice_loss,my_iou_metric,\n",
    "    my_iou_metric_2,IOU_Metric_new,my_iou_metric_bowl,\n",
    "    competition_metric,\n",
    "    iou_bce_loss,lovasz_loss,competition_metric_loss\n",
    ")\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "number_folds = 4\n",
    "weg_train_img = '/mnt/ssd1/dataset/salt/images-train/'\n",
    "weg_train_mask = '/mnt/ssd1/dataset/salt/fixed_train_mask/'\n",
    "weg_train_mask = '/mnt/ssd1/dataset/salt/masks-train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def strong_aug(p=0.5):\n",
    "    return Compose([\n",
    "        HorizontalFlip(),\n",
    "        RandomBrightness(),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0., rotate_limit=5, p=0.75),\n",
    "    ], p=p)\n",
    "augmentation = strong_aug(p=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(value):\n",
    "    return value.replace('.png','')\n",
    "\n",
    "df = pd.read_csv('/mnt/ssd1/dataset/salt/train.csv')\n",
    "df['folds'] = range(len(df))\n",
    "df.folds = df.folds % number_folds\n",
    "\n",
    "train_ids = df.id.values\n",
    "train_folds = df.folds.values\n",
    "df['ids_train_batch'] = train_ids\n",
    "df['fold'] = train_folds\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.read_csv('/mnt/ssd1/dataset/study/split/mainfolds.csv')\n",
    "df1 = pd.read_csv('/mnt/ssd1/dataset/study/split/zerofolds.csv')\n",
    "df = pd.concat((df,df1))\n",
    "train_ids = df.img.values\n",
    "train_ids = np.array(list(map(clean,df.img.values)))\n",
    "train_folds = df.fold.values - 1\n",
    "df['ids_train_batch'] = train_ids\n",
    "df['fold'] = train_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pad(img, pad_size=256, mode=3):\n",
    "    x1 = (pad_size - img.shape[0]) // 2\n",
    "    x2 = pad_size - img.shape[0] - x1\n",
    "\n",
    "    if mode == 0:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, x1, x2, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    if mode == 1:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, x1, x2, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    if mode == 2:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, x1, x2, cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    if mode == 3:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, 0, 0, cv2.BORDER_REPLICATE)\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, x1, x2, cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    if mode == 4:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, 0, 0, cv2.BORDER_REFLECT_101)\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, x1, x2, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "pad = 77\n",
    "load_img = lambda im: np.pad(cv2.imread(join(weg_train_img, '{}.png'.format(im))) #[:,:,0:1]\\\n",
    ", ((pad,pad+1),(pad,pad+1),(0,0)), 'constant')\n",
    "load_mask = lambda im: np.pad(cv2.imread(join(weg_train_mask, '{}.png'.format(im)))[:,:,0]\\\n",
    "                              , ((pad,pad+1),(pad,pad+1)), 'constant')\n",
    "\n",
    "load_img = lambda im: custom_pad(cv2.imread(join(weg_train_img, '{}.png'.format(im))))\n",
    "load_mask = lambda im: custom_pad(cv2.imread(join(weg_train_mask, '{}.png'.format(im)))[:,:,0])\\\n",
    "\n",
    "\n",
    "class ThreadSafeIterator:\n",
    "\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"\n",
    "    A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "\n",
    "    def g(*args, **kwargs):\n",
    "        return ThreadSafeIterator(f(*args, **kwargs))\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "@threadsafe_generator\n",
    "def train_generator(df):\n",
    "    while True:\n",
    "        shuffle_indices = np.arange(len(df))\n",
    "        shuffle_indices = np.random.permutation(shuffle_indices)\n",
    "        \n",
    "        for start in range(0, len(df), BATCH_SIZE):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + BATCH_SIZE, len(df))\n",
    "            ids_train_batch = df.iloc[shuffle_indices[start:end]]\n",
    "            \n",
    "            for _id in ids_train_batch.values:\n",
    "                img = load_img(_id)/ 255.\n",
    "                \n",
    "                mask = load_mask(_id)\n",
    "                mask = np.expand_dims(mask, axis=-1)\n",
    "                mask = mask/255.\n",
    "                assert mask.ndim == 3\n",
    "                \n",
    "                # === You can add data augmentations here. === #\n",
    "                #if np.random.random() < 0.5:\n",
    "                 #   img, mask = img[:, ::-1, :], mask[..., ::-1, :]  # random horizontal flip\n",
    "                data = {\"image\": img, \"mask\": mask}\n",
    "                augmented = augmentation(**data)\n",
    "                img, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "                if len(img.shape) < 3:\n",
    "                    img = np.expand_dims(img, axis=-1)\n",
    "                if len(mask.shape) < 3:\n",
    "                    mask = np.expand_dims(mask, axis=-1)\n",
    "                    \n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            \n",
    "            x_batch = np.array(x_batch, np.float32) \n",
    "            y_batch = np.array(y_batch, np.float32) \n",
    "            \n",
    "\n",
    "            \n",
    "            yield x_batch, y_batch\n",
    "\n",
    "\n",
    "@threadsafe_generator\n",
    "def valid_generator(df):\n",
    "    while True:\n",
    "        for start in range(0, len(df), BATCH_SIZE):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            end = min(start + BATCH_SIZE, len(df))\n",
    "            ids_train_batch = df.iloc[start:end]\n",
    "\n",
    "            for _id in ids_train_batch.values:\n",
    "                img = load_img(_id)\n",
    "                mask = load_mask(_id)\n",
    "\n",
    "\n",
    "                mask = np.expand_dims(mask, axis=-1)\n",
    "                assert mask.ndim == 3\n",
    "                \n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32) / 255.\n",
    "            y_batch = np.array(y_batch, np.float32) / 255.\n",
    "\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs': No such file or directory\n",
      "--------------------------------------------------  FOLD 0 --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n01z3/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train samples in fold 0 is 3000\n",
      "number of validation samples in fold 0 is 1000\n",
      "Epoch 1/10000\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.9975 - acc: 0.6362 - competition_metric: 0.3820 - val_loss: 1.5413 - val_acc: 0.6500 - val_competition_metric: 0.3890\n",
      "\n",
      "Epoch 00001: val_competition_metric improved from -inf to 0.38900, saving model to 1_origina_model_weights_fold_0.hdf5\n",
      "Epoch 2/10000\n",
      "375/375 [==============================] - 58s 155ms/step - loss: 0.8288 - acc: 0.7340 - competition_metric: 0.4582 - val_loss: 1.2900 - val_acc: 0.6122 - val_competition_metric: 0.3350\n",
      "\n",
      "Epoch 00002: val_competition_metric did not improve from 0.38900\n",
      "Epoch 3/10000\n",
      "375/375 [==============================] - 61s 163ms/step - loss: 0.7408 - acc: 0.7549 - competition_metric: 0.5088 - val_loss: 1.3198 - val_acc: 0.5171 - val_competition_metric: 0.2875\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.2.\n",
      "\n",
      "Epoch 00003: val_competition_metric did not improve from 0.38900\n",
      "Epoch 4/10000\n",
      "375/375 [==============================] - 60s 160ms/step - loss: 0.6418 - acc: 0.7654 - competition_metric: 0.5677 - val_loss: 1.3328 - val_acc: 0.6156 - val_competition_metric: 0.3890\n",
      "\n",
      "Epoch 00004: val_competition_metric did not improve from 0.38900\n",
      "Epoch 5/10000\n",
      "375/375 [==============================] - 62s 165ms/step - loss: 0.6201 - acc: 0.7666 - competition_metric: 0.5845 - val_loss: 1.7051 - val_acc: 0.6707 - val_competition_metric: 0.3890\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
      "\n",
      "Epoch 00005: val_competition_metric did not improve from 0.38900\n",
      "Epoch 6/10000\n",
      "375/375 [==============================] - 60s 160ms/step - loss: 0.6001 - acc: 0.7704 - competition_metric: 0.5945 - val_loss: 1.6309 - val_acc: 0.6394 - val_competition_metric: 0.3890\n",
      "\n",
      "Epoch 00006: val_competition_metric did not improve from 0.38900\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 20000\n",
    "BATCH_SIZE = 8\n",
    "!rm -r logs\n",
    "\n",
    "input_1 = 128\n",
    "input_2 = 128\n",
    "for fold_number in [0]:\n",
    "    print ( 50*'-', ' FOLD ' + str(fold_number), 50*'-' )\n",
    "    ids_train = df.ids_train_batch[df.fold != fold_number]\n",
    "    ids_valid = df.ids_train_batch[df.fold == fold_number]\n",
    "\n",
    "    model = Unet(backbone_name='resnet34', encoder_weights='imagenet',input_shape=(256,256,3),freeze_encoder=True,\n",
    "                            decoder_use_batchnorm = True,decoder_block_type = 'upsampling')\n",
    "    model.compile(optimizers.Adadelta(), competition_metric_loss, ['accuracy',competition_metric])\n",
    "\n",
    "\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_competition_metric',\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               min_delta=1e-12,\n",
    "                               mode='max'),\n",
    "                 ReduceLROnPlateau(monitor='val_competition_metric',\n",
    "                                   factor=0.2,\n",
    "                                   patience=2,\n",
    "                                   verbose=1,\n",
    "                                   epsilon=1e-12,\n",
    "                                   mode='max'),\n",
    "                 ModelCheckpoint(monitor='val_competition_metric',\n",
    "                                 filepath='1_origina_model_weights_fold_{}.hdf5'.format(fold_number),\n",
    "                                 save_best_only=True,verbose = 1,\n",
    "                                 mode='max')]\n",
    "    print('number of train samples in fold ' +str(fold_number) + ' is ' + str(len(ids_train)))\n",
    "    print('number of validation samples in fold ' +str(fold_number) + ' is ' + str(len(ids_valid)))\n",
    "    \n",
    "    #model.load_weights('AUTOENCODER.hdf5'.format(fold_number))\n",
    "    model.fit_generator(generator=train_generator(ids_train),\n",
    "                        steps_per_epoch=np.ceil(float(len(ids_train)) / float(BATCH_SIZE)),\n",
    "                        epochs=10000,\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=valid_generator(ids_valid),\n",
    "                        validation_steps=np.ceil(float(len(ids_valid)) / float(BATCH_SIZE)))\n",
    "    \n",
    "    del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs': No such file or directory\n",
      "--------------------------------------------------  FOLD 0 --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n01z3/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train samples in fold 0 is 3000\n",
      "number of validation samples in fold 0 is 1000\n",
      "Epoch 1/10000\n",
      "188/188 [==============================] - 120s 638ms/step - loss: 0.3343 - acc: 0.7047 - competition_metric: 0.5237 - val_loss: 0.3659 - val_acc: 0.6672 - val_competition_metric: 0.5606\n",
      "\n",
      "Epoch 00001: val_competition_metric improved from -inf to 0.56060, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 2/10000\n",
      "188/188 [==============================] - 72s 385ms/step - loss: 0.2551 - acc: 0.7189 - competition_metric: 0.6344 - val_loss: 0.2594 - val_acc: 0.7335 - val_competition_metric: 0.6472\n",
      "\n",
      "Epoch 00002: val_competition_metric improved from 0.56060 to 0.64720, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 3/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.2142 - acc: 0.7331 - competition_metric: 0.6884 - val_loss: 0.2335 - val_acc: 0.7554 - val_competition_metric: 0.6982\n",
      "\n",
      "Epoch 00003: val_competition_metric improved from 0.64720 to 0.69820, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 4/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.1769 - acc: 0.7321 - competition_metric: 0.7195 - val_loss: 0.2214 - val_acc: 0.7656 - val_competition_metric: 0.7024\n",
      "\n",
      "Epoch 00004: val_competition_metric improved from 0.69820 to 0.70240, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 5/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.1622 - acc: 0.7330 - competition_metric: 0.7313 - val_loss: 0.2275 - val_acc: 0.7274 - val_competition_metric: 0.7054\n",
      "\n",
      "Epoch 00005: val_competition_metric improved from 0.70240 to 0.70540, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 6/10000\n",
      "188/188 [==============================] - 74s 392ms/step - loss: 0.1584 - acc: 0.7435 - competition_metric: 0.7367 - val_loss: 0.2131 - val_acc: 0.7732 - val_competition_metric: 0.7252\n",
      "\n",
      "Epoch 00006: val_competition_metric improved from 0.70540 to 0.72520, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 7/10000\n",
      "188/188 [==============================] - 74s 393ms/step - loss: 0.1474 - acc: 0.7394 - competition_metric: 0.7506 - val_loss: 0.2082 - val_acc: 0.7478 - val_competition_metric: 0.7077\n",
      "\n",
      "Epoch 00007: val_competition_metric did not improve from 0.72520\n",
      "Epoch 8/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.1278 - acc: 0.7414 - competition_metric: 0.7672 - val_loss: 0.2181 - val_acc: 0.7161 - val_competition_metric: 0.7309\n",
      "\n",
      "Epoch 00008: val_competition_metric improved from 0.72520 to 0.73090, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 9/10000\n",
      "188/188 [==============================] - 74s 393ms/step - loss: 0.1246 - acc: 0.7361 - competition_metric: 0.7779 - val_loss: 0.2345 - val_acc: 0.7267 - val_competition_metric: 0.7221\n",
      "\n",
      "Epoch 00009: val_competition_metric did not improve from 0.73090\n",
      "Epoch 10/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.1068 - acc: 0.7369 - competition_metric: 0.7947 - val_loss: 0.2034 - val_acc: 0.7128 - val_competition_metric: 0.7352\n",
      "\n",
      "Epoch 00010: val_competition_metric improved from 0.73090 to 0.73520, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 11/10000\n",
      "188/188 [==============================] - 74s 392ms/step - loss: 0.1039 - acc: 0.7208 - competition_metric: 0.7925 - val_loss: 0.2209 - val_acc: 0.7266 - val_competition_metric: 0.7318\n",
      "\n",
      "Epoch 00011: val_competition_metric did not improve from 0.73520\n",
      "Epoch 12/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0870 - acc: 0.7310 - competition_metric: 0.8179 - val_loss: 0.2443 - val_acc: 0.6841 - val_competition_metric: 0.7211\n",
      "\n",
      "Epoch 00012: val_competition_metric did not improve from 0.73520\n",
      "Epoch 13/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0858 - acc: 0.7268 - competition_metric: 0.8165 - val_loss: 0.4360 - val_acc: 0.7614 - val_competition_metric: 0.7336\n",
      "\n",
      "Epoch 00013: val_competition_metric did not improve from 0.73520\n",
      "Epoch 14/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0816 - acc: 0.7114 - competition_metric: 0.8157 - val_loss: 0.2107 - val_acc: 0.7283 - val_competition_metric: 0.7596\n",
      "\n",
      "Epoch 00014: val_competition_metric improved from 0.73520 to 0.75960, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 15/10000\n",
      "188/188 [==============================] - 74s 392ms/step - loss: 0.0693 - acc: 0.7141 - competition_metric: 0.8424 - val_loss: 0.2315 - val_acc: 0.6599 - val_competition_metric: 0.7454\n",
      "\n",
      "Epoch 00015: val_competition_metric did not improve from 0.75960\n",
      "Epoch 16/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0786 - acc: 0.7166 - competition_metric: 0.8217 - val_loss: 0.2607 - val_acc: 0.7354 - val_competition_metric: 0.7401\n",
      "\n",
      "Epoch 00016: val_competition_metric did not improve from 0.75960\n",
      "Epoch 17/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0809 - acc: 0.7077 - competition_metric: 0.8274 - val_loss: 0.2263 - val_acc: 0.6856 - val_competition_metric: 0.7330\n",
      "\n",
      "Epoch 00017: val_competition_metric did not improve from 0.75960\n",
      "Epoch 18/10000\n",
      "188/188 [==============================] - 74s 393ms/step - loss: 0.0759 - acc: 0.7179 - competition_metric: 0.8359 - val_loss: 0.2269 - val_acc: 0.7000 - val_competition_metric: 0.7489\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 00018: val_competition_metric did not improve from 0.75960\n",
      "Epoch 19/10000\n",
      "188/188 [==============================] - 73s 388ms/step - loss: 0.0587 - acc: 0.7077 - competition_metric: 0.8458 - val_loss: 0.2184 - val_acc: 0.6853 - val_competition_metric: 0.7714\n",
      "\n",
      "Epoch 00019: val_competition_metric improved from 0.75960 to 0.77140, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 20/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0517 - acc: 0.7075 - competition_metric: 0.8587 - val_loss: 0.2259 - val_acc: 0.6854 - val_competition_metric: 0.7703\n",
      "\n",
      "Epoch 00020: val_competition_metric did not improve from 0.77140\n",
      "Epoch 21/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0507 - acc: 0.7069 - competition_metric: 0.8567 - val_loss: 0.2271 - val_acc: 0.6760 - val_competition_metric: 0.7729\n",
      "\n",
      "Epoch 00021: val_competition_metric improved from 0.77140 to 0.77290, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 22/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0480 - acc: 0.7038 - competition_metric: 0.8677 - val_loss: 0.2330 - val_acc: 0.6756 - val_competition_metric: 0.7745\n",
      "\n",
      "Epoch 00022: val_competition_metric improved from 0.77290 to 0.77450, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 23/10000\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.0452 - acc: 0.7010 - competition_metric: 0.8719 - val_loss: 0.2325 - val_acc: 0.6736 - val_competition_metric: 0.7785\n",
      "\n",
      "Epoch 00023: val_competition_metric improved from 0.77450 to 0.77850, saving model to 2_origina_model_weights_fold_0.hdf5\n",
      "Epoch 24/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0435 - acc: 0.6912 - competition_metric: 0.8737 - val_loss: 0.2253 - val_acc: 0.6749 - val_competition_metric: 0.7832\n",
      "\n",
      "Epoch 00025: val_competition_metric did not improve from 0.78560\n",
      "Epoch 26/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0451 - acc: 0.6850 - competition_metric: 0.8714 - val_loss: 0.2268 - val_acc: 0.6626 - val_competition_metric: 0.7761\n",
      "\n",
      "Epoch 00026: val_competition_metric did not improve from 0.78560\n",
      "Epoch 27/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0424 - acc: 0.6831 - competition_metric: 0.8730 - val_loss: 0.2477 - val_acc: 0.6766 - val_competition_metric: 0.7736\n",
      "\n",
      "Epoch 00027: val_competition_metric did not improve from 0.78560\n",
      "Epoch 28/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0412 - acc: 0.6809 - competition_metric: 0.8762 - val_loss: 0.2378 - val_acc: 0.6551 - val_competition_metric: 0.7667\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 00028: val_competition_metric did not improve from 0.78560\n",
      "Epoch 29/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0394 - acc: 0.6801 - competition_metric: 0.8881 - val_loss: 0.2363 - val_acc: 0.6599 - val_competition_metric: 0.7743\n",
      "\n",
      "Epoch 00029: val_competition_metric did not improve from 0.78560\n",
      "Epoch 30/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0385 - acc: 0.6805 - competition_metric: 0.8830 - val_loss: 0.2378 - val_acc: 0.6612 - val_competition_metric: 0.7730\n",
      "\n",
      "Epoch 00030: val_competition_metric did not improve from 0.78560\n",
      "Epoch 31/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0389 - acc: 0.6812 - competition_metric: 0.8800 - val_loss: 0.2373 - val_acc: 0.6575 - val_competition_metric: 0.7741\n",
      "\n",
      "Epoch 00031: val_competition_metric did not improve from 0.78560\n",
      "Epoch 32/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0389 - acc: 0.6808 - competition_metric: 0.8829 - val_loss: 0.2390 - val_acc: 0.6621 - val_competition_metric: 0.7725\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\n",
      "Epoch 00032: val_competition_metric did not improve from 0.78560\n",
      "Epoch 33/10000\n",
      "188/188 [==============================] - 74s 393ms/step - loss: 0.0383 - acc: 0.6795 - competition_metric: 0.8823 - val_loss: 0.2392 - val_acc: 0.6617 - val_competition_metric: 0.7729\n",
      "\n",
      "Epoch 00033: val_competition_metric did not improve from 0.78560\n",
      "Epoch 34/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0370 - acc: 0.6801 - competition_metric: 0.8867 - val_loss: 0.2393 - val_acc: 0.6594 - val_competition_metric: 0.7719\n",
      "\n",
      "Epoch 00034: val_competition_metric did not improve from 0.78560\n",
      "Epoch 35/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0375 - acc: 0.6800 - competition_metric: 0.8888 - val_loss: 0.2402 - val_acc: 0.6590 - val_competition_metric: 0.7724\n",
      "\n",
      "Epoch 00035: val_competition_metric did not improve from 0.78560\n",
      "Epoch 36/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0379 - acc: 0.6805 - competition_metric: 0.8851 - val_loss: 0.2399 - val_acc: 0.6604 - val_competition_metric: 0.7739\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 00036: val_competition_metric did not improve from 0.78560\n",
      "Epoch 37/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0378 - acc: 0.6794 - competition_metric: 0.8836 - val_loss: 0.2410 - val_acc: 0.6605 - val_competition_metric: 0.7743\n",
      "\n",
      "Epoch 00037: val_competition_metric did not improve from 0.78560\n",
      "Epoch 38/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0361 - acc: 0.6791 - competition_metric: 0.8850 - val_loss: 0.2406 - val_acc: 0.6617 - val_competition_metric: 0.7751\n",
      "\n",
      "Epoch 00038: val_competition_metric did not improve from 0.78560\n",
      "Epoch 39/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0373 - acc: 0.6806 - competition_metric: 0.8855 - val_loss: 0.2404 - val_acc: 0.6618 - val_competition_metric: 0.7742\n",
      "\n",
      "Epoch 00039: val_competition_metric did not improve from 0.78560\n",
      "Epoch 40/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0377 - acc: 0.6793 - competition_metric: 0.8854 - val_loss: 0.2410 - val_acc: 0.6597 - val_competition_metric: 0.7744\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\n",
      "Epoch 00040: val_competition_metric did not improve from 0.78560\n",
      "Epoch 41/10000\n",
      "163/188 [=========================>....] - ETA: 8s - loss: 0.0373 - acc: 0.6801 - competition_metric: 0.8844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0420 - acc: 0.6984 - competition_metric: 0.8782 - val_loss: 0.2254 - val_acc: 0.6739 - val_competition_metric: 0.7869\n",
      "\n",
      "Epoch 00025: val_competition_metric did not improve from 0.79130\n",
      "Epoch 26/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0405 - acc: 0.6985 - competition_metric: 0.8827 - val_loss: 0.2264 - val_acc: 0.6737 - val_competition_metric: 0.7860\n",
      "\n",
      "Epoch 00026: val_competition_metric did not improve from 0.79130\n",
      "Epoch 27/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0403 - acc: 0.6891 - competition_metric: 0.8854 - val_loss: 0.2346 - val_acc: 0.6671 - val_competition_metric: 0.7797\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 00027: val_competition_metric did not improve from 0.79130\n",
      "Epoch 28/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0387 - acc: 0.6839 - competition_metric: 0.8878 - val_loss: 0.2320 - val_acc: 0.6629 - val_competition_metric: 0.7826\n",
      "\n",
      "Epoch 00028: val_competition_metric did not improve from 0.79130\n",
      "Epoch 29/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0380 - acc: 0.6870 - competition_metric: 0.8856 - val_loss: 0.2335 - val_acc: 0.6631 - val_competition_metric: 0.7847\n",
      "\n",
      "Epoch 00029: val_competition_metric did not improve from 0.79130\n",
      "Epoch 30/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0373 - acc: 0.6883 - competition_metric: 0.8928 - val_loss: 0.2324 - val_acc: 0.6607 - val_competition_metric: 0.7852\n",
      "\n",
      "Epoch 00030: val_competition_metric did not improve from 0.79130\n",
      "Epoch 31/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0363 - acc: 0.6864 - competition_metric: 0.8891 - val_loss: 0.2329 - val_acc: 0.6602 - val_competition_metric: 0.7840\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\n",
      "Epoch 00031: val_competition_metric did not improve from 0.79130\n",
      "Epoch 32/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0354 - acc: 0.6877 - competition_metric: 0.8921 - val_loss: 0.2351 - val_acc: 0.6588 - val_competition_metric: 0.7849\n",
      "\n",
      "Epoch 00032: val_competition_metric did not improve from 0.79130\n",
      "Epoch 33/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0367 - acc: 0.6864 - competition_metric: 0.8887 - val_loss: 0.2344 - val_acc: 0.6576 - val_competition_metric: 0.7858\n",
      "\n",
      "Epoch 00033: val_competition_metric did not improve from 0.79130\n",
      "Epoch 34/10000\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.0367 - acc: 0.6857 - competition_metric: 0.8914 - val_loss: 0.2333 - val_acc: 0.6593 - val_competition_metric: 0.7848\n",
      "\n",
      "Epoch 00034: val_competition_metric did not improve from 0.79130\n",
      "Epoch 35/10000\n",
      "188/188 [==============================] - 75s 400ms/step - loss: 0.0360 - acc: 0.6854 - competition_metric: 0.8899 - val_loss: 0.2341 - val_acc: 0.6590 - val_competition_metric: 0.7879\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 00035: val_competition_metric did not improve from 0.79130\n",
      "Epoch 36/10000\n",
      "188/188 [==============================] - 75s 401ms/step - loss: 0.0363 - acc: 0.6843 - competition_metric: 0.8880 - val_loss: 0.2349 - val_acc: 0.6607 - val_competition_metric: 0.7866\n",
      "\n",
      "Epoch 00036: val_competition_metric did not improve from 0.79130\n",
      "Epoch 37/10000\n",
      "188/188 [==============================] - 76s 402ms/step - loss: 0.0352 - acc: 0.6850 - competition_metric: 0.8897 - val_loss: 0.2349 - val_acc: 0.6588 - val_competition_metric: 0.7858\n",
      "\n",
      "Epoch 00037: val_competition_metric did not improve from 0.79130\n",
      "Epoch 38/10000\n",
      "188/188 [==============================] - 75s 401ms/step - loss: 0.0361 - acc: 0.6857 - competition_metric: 0.8892 - val_loss: 0.2357 - val_acc: 0.6600 - val_competition_metric: 0.7861\n",
      "\n",
      "Epoch 00038: val_competition_metric did not improve from 0.79130\n",
      "Epoch 39/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0361 - acc: 0.6851 - competition_metric: 0.8913 - val_loss: 0.2353 - val_acc: 0.6592 - val_competition_metric: 0.7850\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\n",
      "Epoch 00039: val_competition_metric did not improve from 0.79130\n",
      "Epoch 40/10000\n",
      "188/188 [==============================] - 74s 393ms/step - loss: 0.0362 - acc: 0.6863 - competition_metric: 0.8907 - val_loss: 0.2341 - val_acc: 0.6587 - val_competition_metric: 0.7861\n",
      "\n",
      "Epoch 00040: val_competition_metric did not improve from 0.79130\n",
      "Epoch 41/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0355 - acc: 0.6837 - competition_metric: 0.8919 - val_loss: 0.2353 - val_acc: 0.6595 - val_competition_metric: 0.7861\n",
      "\n",
      "Epoch 00041: val_competition_metric did not improve from 0.79130\n",
      "Epoch 42/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0360 - acc: 0.6856 - competition_metric: 0.8924 - val_loss: 0.2346 - val_acc: 0.6583 - val_competition_metric: 0.7853\n",
      "\n",
      "Epoch 00042: val_competition_metric did not improve from 0.79130\n",
      "Epoch 43/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0360 - acc: 0.6862 - competition_metric: 0.8906 - val_loss: 0.2352 - val_acc: 0.6592 - val_competition_metric: 0.7872\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "\n",
      "Epoch 00043: val_competition_metric did not improve from 0.79130\n",
      "Epoch 00043: early stopping\n"
     ]
    }
   ],
   "source": [
    "# epochs = 20000\n",
    "BATCH_SIZE = 16\n",
    "!rm -r logs\n",
    "\n",
    "input_1 = 128\n",
    "input_2 = 128\n",
    "for fold_number in [0,1]:\n",
    "    print ( 50*'-', ' FOLD ' + str(fold_number), 50*'-' )\n",
    "    ids_train = df.ids_train_batch[df.fold != fold_number]\n",
    "    ids_valid = df.ids_train_batch[df.fold == fold_number]\n",
    "\n",
    "    model = Unet(backbone_name='resnet34', encoder_weights='imagenet',input_shape=(256,256,3),freeze_encoder=False,\n",
    "                            decoder_use_batchnorm = True,decoder_block_type = 'upsampling')\n",
    "    model.compile(optimizers.Adam(lr = 0.0001), bce_dice_loss, ['accuracy',competition_metric])\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_competition_metric',\n",
    "                               patience=20,\n",
    "                               verbose=1,\n",
    "                               min_delta=1e-12,\n",
    "                               mode='max'),\n",
    "                 ReduceLROnPlateau(monitor='val_competition_metric',\n",
    "                                   factor=0.2,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   epsilon=1e-12,\n",
    "                                   mode='max'),\n",
    "                 ModelCheckpoint(monitor='val_competition_metric',\n",
    "                                 filepath='2_origina_model_weights_fold_{}.hdf5'.format(fold_number),\n",
    "                                 save_best_only=True,verbose = 1,\n",
    "                                 mode='max')]\n",
    "    print('number of train samples in fold ' +str(fold_number) + ' is ' + str(len(ids_train)))\n",
    "    print('number of validation samples in fold ' +str(fold_number) + ' is ' + str(len(ids_valid)))\n",
    "    \n",
    "    model.load_weights('1_origina_model_weights_fold_{}.hdf5'.format(fold_number))\n",
    "    #model.load_weights('AUTOENCODER.hdf5'.format(fold_number))\n",
    "    model.fit_generator(generator=train_generator(ids_train),\n",
    "                        steps_per_epoch=np.ceil(float(len(ids_train)) / float(BATCH_SIZE)),\n",
    "                        epochs=10000,\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=valid_generator(ids_valid),\n",
    "                        validation_steps=np.ceil(float(len(ids_valid)) / float(BATCH_SIZE)))\n",
    "    \n",
    "    del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------  FOLD 0 --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n01z3/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train samples in fold 0 is 3000\n",
      "number of validation samples in fold 0 is 1000\n",
      "Epoch 1/10000\n",
      "188/188 [==============================] - 125s 665ms/step - loss: 0.3368 - acc: 0.7126 - competition_metric: 0.5291 - val_loss: 0.2955 - val_acc: 0.7118 - val_competition_metric: 0.6178\n",
      "\n",
      "Epoch 00001: val_competition_metric improved from -inf to 0.61780, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 2/10000\n",
      "188/188 [==============================] - 76s 406ms/step - loss: 0.2533 - acc: 0.7228 - competition_metric: 0.6376 - val_loss: 0.2570 - val_acc: 0.7384 - val_competition_metric: 0.6457\n",
      "\n",
      "Epoch 00002: val_competition_metric improved from 0.61780 to 0.64570, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 3/10000\n",
      "188/188 [==============================] - 76s 405ms/step - loss: 0.2073 - acc: 0.7167 - competition_metric: 0.6823 - val_loss: 0.2323 - val_acc: 0.7289 - val_competition_metric: 0.6770\n",
      "\n",
      "Epoch 00003: val_competition_metric improved from 0.64570 to 0.67700, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 4/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.1802 - acc: 0.7219 - competition_metric: 0.7264 - val_loss: 0.2278 - val_acc: 0.7252 - val_competition_metric: 0.7080\n",
      "\n",
      "Epoch 00004: val_competition_metric improved from 0.67700 to 0.70800, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 5/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.1723 - acc: 0.7145 - competition_metric: 0.7273 - val_loss: 0.2170 - val_acc: 0.7529 - val_competition_metric: 0.7126\n",
      "\n",
      "Epoch 00005: val_competition_metric improved from 0.70800 to 0.71260, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 6/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.1530 - acc: 0.7286 - competition_metric: 0.7481 - val_loss: 0.2185 - val_acc: 0.7555 - val_competition_metric: 0.7115\n",
      "\n",
      "Epoch 00006: val_competition_metric did not improve from 0.71260\n",
      "Epoch 7/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.1296 - acc: 0.7343 - competition_metric: 0.7689 - val_loss: 0.2418 - val_acc: 0.7353 - val_competition_metric: 0.7228\n",
      "\n",
      "Epoch 00007: val_competition_metric improved from 0.71260 to 0.72280, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 8/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.1227 - acc: 0.7357 - competition_metric: 0.7778 - val_loss: 0.2334 - val_acc: 0.7366 - val_competition_metric: 0.7034\n",
      "\n",
      "Epoch 00008: val_competition_metric did not improve from 0.72280\n",
      "Epoch 9/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.1082 - acc: 0.7388 - competition_metric: 0.7862 - val_loss: 0.2284 - val_acc: 0.6980 - val_competition_metric: 0.7380\n",
      "\n",
      "Epoch 00009: val_competition_metric improved from 0.72280 to 0.73800, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 10/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.1023 - acc: 0.7341 - competition_metric: 0.7974 - val_loss: 0.2002 - val_acc: 0.7234 - val_competition_metric: 0.7313\n",
      "\n",
      "Epoch 00010: val_competition_metric did not improve from 0.73800\n",
      "Epoch 11/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0992 - acc: 0.7251 - competition_metric: 0.8004 - val_loss: 0.2330 - val_acc: 0.7365 - val_competition_metric: 0.7523\n",
      "\n",
      "Epoch 00011: val_competition_metric improved from 0.73800 to 0.75230, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 12/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0911 - acc: 0.7302 - competition_metric: 0.8158 - val_loss: 0.2396 - val_acc: 0.7338 - val_competition_metric: 0.7283\n",
      "\n",
      "Epoch 00012: val_competition_metric did not improve from 0.75230\n",
      "Epoch 13/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0977 - acc: 0.7218 - competition_metric: 0.8092 - val_loss: 0.2238 - val_acc: 0.6813 - val_competition_metric: 0.7377\n",
      "\n",
      "Epoch 00013: val_competition_metric did not improve from 0.75230\n",
      "Epoch 14/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0843 - acc: 0.7441 - competition_metric: 0.8241 - val_loss: 0.2142 - val_acc: 0.7164 - val_competition_metric: 0.7615\n",
      "\n",
      "Epoch 00014: val_competition_metric improved from 0.75230 to 0.76150, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 15/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0840 - acc: 0.7310 - competition_metric: 0.8272 - val_loss: 0.2244 - val_acc: 0.6924 - val_competition_metric: 0.7414\n",
      "\n",
      "Epoch 00015: val_competition_metric did not improve from 0.76150\n",
      "Epoch 16/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0880 - acc: 0.7178 - competition_metric: 0.8165 - val_loss: 0.2635 - val_acc: 0.7323 - val_competition_metric: 0.7505\n",
      "\n",
      "Epoch 00016: val_competition_metric did not improve from 0.76150\n",
      "Epoch 17/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0868 - acc: 0.7326 - competition_metric: 0.8198 - val_loss: 0.2653 - val_acc: 0.7079 - val_competition_metric: 0.7552\n",
      "\n",
      "Epoch 00017: val_competition_metric did not improve from 0.76150\n",
      "Epoch 18/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0778 - acc: 0.7172 - competition_metric: 0.8255 - val_loss: 0.2413 - val_acc: 0.7122 - val_competition_metric: 0.7571\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 00018: val_competition_metric did not improve from 0.76150\n",
      "Epoch 19/10000\n",
      "188/188 [==============================] - 73s 386ms/step - loss: 0.0636 - acc: 0.7041 - competition_metric: 0.8463 - val_loss: 0.2279 - val_acc: 0.6839 - val_competition_metric: 0.7712\n",
      "\n",
      "Epoch 00019: val_competition_metric improved from 0.76150 to 0.77120, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 20/10000\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.0537 - acc: 0.7082 - competition_metric: 0.8598 - val_loss: 0.2315 - val_acc: 0.6854 - val_competition_metric: 0.7767\n",
      "\n",
      "Epoch 00020: val_competition_metric improved from 0.77120 to 0.77670, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 21/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0537 - acc: 0.7077 - competition_metric: 0.8586 - val_loss: 0.2227 - val_acc: 0.6941 - val_competition_metric: 0.7819\n",
      "\n",
      "Epoch 00021: val_competition_metric improved from 0.77670 to 0.78190, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 22/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0495 - acc: 0.7000 - competition_metric: 0.8657 - val_loss: 0.2255 - val_acc: 0.6905 - val_competition_metric: 0.7828\n",
      "\n",
      "Epoch 00022: val_competition_metric improved from 0.78190 to 0.78280, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 23/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0471 - acc: 0.6942 - competition_metric: 0.8697 - val_loss: 0.2276 - val_acc: 0.6872 - val_competition_metric: 0.7831\n",
      "\n",
      "Epoch 00023: val_competition_metric improved from 0.78280 to 0.78310, saving model to 3_origina_model_weights_fold_0.hdf5\n",
      "Epoch 24/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0472 - acc: 0.6915 - competition_metric: 0.8661 - val_loss: 0.2398 - val_acc: 0.6746 - val_competition_metric: 0.7826\n",
      "\n",
      "Epoch 00024: val_competition_metric did not improve from 0.78310\n",
      "Epoch 25/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0441 - acc: 0.6862 - competition_metric: 0.8708 - val_loss: 0.2420 - val_acc: 0.6838 - val_competition_metric: 0.7808\n",
      "\n",
      "Epoch 00025: val_competition_metric did not improve from 0.78310\n",
      "Epoch 26/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0471 - acc: 0.6852 - competition_metric: 0.8729 - val_loss: 0.2393 - val_acc: 0.6766 - val_competition_metric: 0.7776\n",
      "\n",
      "Epoch 00026: val_competition_metric did not improve from 0.78310\n",
      "Epoch 27/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0436 - acc: 0.6874 - competition_metric: 0.8736 - val_loss: 0.2329 - val_acc: 0.6654 - val_competition_metric: 0.7790\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 00027: val_competition_metric did not improve from 0.78310\n",
      "Epoch 28/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0427 - acc: 0.6856 - competition_metric: 0.8757 - val_loss: 0.2331 - val_acc: 0.6727 - val_competition_metric: 0.7817\n",
      "\n",
      "Epoch 00028: val_competition_metric did not improve from 0.78310\n",
      "Epoch 29/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0415 - acc: 0.6835 - competition_metric: 0.8789 - val_loss: 0.2349 - val_acc: 0.6694 - val_competition_metric: 0.7817\n",
      "\n",
      "Epoch 00029: val_competition_metric did not improve from 0.78310\n",
      "Epoch 30/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0405 - acc: 0.6805 - competition_metric: 0.8807 - val_loss: 0.2366 - val_acc: 0.6645 - val_competition_metric: 0.7805\n",
      "\n",
      "Epoch 00030: val_competition_metric did not improve from 0.78310\n",
      "Epoch 31/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0403 - acc: 0.6776 - competition_metric: 0.8788 - val_loss: 0.2393 - val_acc: 0.6644 - val_competition_metric: 0.7803\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\n",
      "Epoch 00031: val_competition_metric did not improve from 0.78310\n",
      "Epoch 32/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0387 - acc: 0.6791 - competition_metric: 0.8867 - val_loss: 0.2404 - val_acc: 0.6667 - val_competition_metric: 0.7813\n",
      "\n",
      "Epoch 00032: val_competition_metric did not improve from 0.78310\n",
      "Epoch 33/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0399 - acc: 0.6781 - competition_metric: 0.8818 - val_loss: 0.2415 - val_acc: 0.6681 - val_competition_metric: 0.7807\n",
      "\n",
      "Epoch 00033: val_competition_metric did not improve from 0.78310\n",
      "Epoch 34/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0401 - acc: 0.6773 - competition_metric: 0.8826 - val_loss: 0.2415 - val_acc: 0.6640 - val_competition_metric: 0.7807\n",
      "\n",
      "Epoch 00034: val_competition_metric did not improve from 0.78310\n",
      "Epoch 35/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0395 - acc: 0.6780 - competition_metric: 0.8837 - val_loss: 0.2413 - val_acc: 0.6632 - val_competition_metric: 0.7805\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 00035: val_competition_metric did not improve from 0.78310\n",
      "Epoch 36/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0395 - acc: 0.6791 - competition_metric: 0.8825 - val_loss: 0.2395 - val_acc: 0.6657 - val_competition_metric: 0.7806\n",
      "\n",
      "Epoch 00036: val_competition_metric did not improve from 0.78310\n",
      "Epoch 37/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0399 - acc: 0.6786 - competition_metric: 0.8820 - val_loss: 0.2402 - val_acc: 0.6657 - val_competition_metric: 0.7804\n",
      "\n",
      "Epoch 00037: val_competition_metric did not improve from 0.78310\n",
      "Epoch 38/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0386 - acc: 0.6788 - competition_metric: 0.8838 - val_loss: 0.2415 - val_acc: 0.6642 - val_competition_metric: 0.7814\n",
      "\n",
      "Epoch 00038: val_competition_metric did not improve from 0.78310\n",
      "Epoch 39/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0392 - acc: 0.6784 - competition_metric: 0.8831 - val_loss: 0.2415 - val_acc: 0.6653 - val_competition_metric: 0.7797\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\n",
      "Epoch 00039: val_competition_metric did not improve from 0.78310\n",
      "Epoch 40/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0392 - acc: 0.6785 - competition_metric: 0.8826 - val_loss: 0.2401 - val_acc: 0.6651 - val_competition_metric: 0.7814\n",
      "\n",
      "Epoch 00040: val_competition_metric did not improve from 0.78310\n",
      "Epoch 41/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0394 - acc: 0.6781 - competition_metric: 0.8809 - val_loss: 0.2412 - val_acc: 0.6652 - val_competition_metric: 0.7808\n",
      "\n",
      "Epoch 00041: val_competition_metric did not improve from 0.78310\n",
      "Epoch 42/10000\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.0397 - acc: 0.6778 - competition_metric: 0.8820 - val_loss: 0.2417 - val_acc: 0.6654 - val_competition_metric: 0.7815\n",
      "\n",
      "Epoch 00042: val_competition_metric did not improve from 0.78310\n",
      "Epoch 43/10000\n",
      "188/188 [==============================] - 75s 400ms/step - loss: 0.0396 - acc: 0.6788 - competition_metric: 0.8792 - val_loss: 0.2409 - val_acc: 0.6668 - val_competition_metric: 0.7813\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "\n",
      "Epoch 00043: val_competition_metric did not improve from 0.78310\n",
      "Epoch 00043: early stopping\n",
      "--------------------------------------------------  FOLD 1 --------------------------------------------------\n",
      "number of train samples in fold 1 is 3000\n",
      "number of validation samples in fold 1 is 1000\n",
      "Epoch 1/10000\n",
      "188/188 [==============================] - 131s 696ms/step - loss: 0.3198 - acc: 0.6274 - competition_metric: 0.5809 - val_loss: 0.2770 - val_acc: 0.6685 - val_competition_metric: 0.6717\n",
      "\n",
      "Epoch 00001: val_competition_metric improved from -inf to 0.67170, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 2/10000\n",
      "188/188 [==============================] - 73s 389ms/step - loss: 0.2424 - acc: 0.6493 - competition_metric: 0.6638 - val_loss: 0.2963 - val_acc: 0.6347 - val_competition_metric: 0.5711\n",
      "\n",
      "Epoch 00002: val_competition_metric did not improve from 0.67170\n",
      "Epoch 3/10000\n",
      "188/188 [==============================] - 75s 400ms/step - loss: 0.2081 - acc: 0.6690 - competition_metric: 0.7085 - val_loss: 0.2169 - val_acc: 0.6877 - val_competition_metric: 0.7124\n",
      "\n",
      "Epoch 00003: val_competition_metric improved from 0.67170 to 0.71240, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 4/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.1664 - acc: 0.6795 - competition_metric: 0.7481 - val_loss: 0.2120 - val_acc: 0.6953 - val_competition_metric: 0.7153\n",
      "\n",
      "Epoch 00004: val_competition_metric improved from 0.71240 to 0.71530, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 5/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.1401 - acc: 0.6815 - competition_metric: 0.7642 - val_loss: 0.2271 - val_acc: 0.6703 - val_competition_metric: 0.7169\n",
      "\n",
      "Epoch 00005: val_competition_metric improved from 0.71530 to 0.71690, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 6/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.1340 - acc: 0.7111 - competition_metric: 0.7566 - val_loss: 0.2349 - val_acc: 0.7305 - val_competition_metric: 0.7395\n",
      "\n",
      "Epoch 00006: val_competition_metric improved from 0.71690 to 0.73950, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 7/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.1339 - acc: 0.7075 - competition_metric: 0.7746 - val_loss: 0.2359 - val_acc: 0.6586 - val_competition_metric: 0.7450\n",
      "\n",
      "Epoch 00007: val_competition_metric improved from 0.73950 to 0.74500, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 8/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.1115 - acc: 0.7151 - competition_metric: 0.7955 - val_loss: 0.2684 - val_acc: 0.6864 - val_competition_metric: 0.7321\n",
      "\n",
      "Epoch 00008: val_competition_metric did not improve from 0.74500\n",
      "Epoch 9/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0974 - acc: 0.7233 - competition_metric: 0.8067 - val_loss: 0.2318 - val_acc: 0.7549 - val_competition_metric: 0.7221\n",
      "\n",
      "Epoch 00009: val_competition_metric did not improve from 0.74500\n",
      "Epoch 10/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0999 - acc: 0.7173 - competition_metric: 0.8057 - val_loss: 0.2335 - val_acc: 0.6777 - val_competition_metric: 0.7531\n",
      "\n",
      "Epoch 00010: val_competition_metric improved from 0.74500 to 0.75310, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 11/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0952 - acc: 0.7278 - competition_metric: 0.8140 - val_loss: 0.2418 - val_acc: 0.6882 - val_competition_metric: 0.7403\n",
      "\n",
      "Epoch 00011: val_competition_metric did not improve from 0.75310\n",
      "Epoch 12/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0926 - acc: 0.7300 - competition_metric: 0.8168 - val_loss: 0.2651 - val_acc: 0.6526 - val_competition_metric: 0.7237\n",
      "\n",
      "Epoch 00012: val_competition_metric did not improve from 0.75310\n",
      "Epoch 13/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0913 - acc: 0.7101 - competition_metric: 0.8204 - val_loss: 0.2519 - val_acc: 0.6905 - val_competition_metric: 0.6995\n",
      "\n",
      "Epoch 00013: val_competition_metric did not improve from 0.75310\n",
      "Epoch 14/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0774 - acc: 0.7096 - competition_metric: 0.8175 - val_loss: 0.2373 - val_acc: 0.6690 - val_competition_metric: 0.7503\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 00014: val_competition_metric did not improve from 0.75310\n",
      "Epoch 15/10000\n",
      "188/188 [==============================] - 74s 392ms/step - loss: 0.0630 - acc: 0.7106 - competition_metric: 0.8447 - val_loss: 0.2278 - val_acc: 0.6779 - val_competition_metric: 0.7693\n",
      "\n",
      "Epoch 00015: val_competition_metric improved from 0.75310 to 0.76930, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 16/10000\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.0563 - acc: 0.7048 - competition_metric: 0.8535 - val_loss: 0.2215 - val_acc: 0.6895 - val_competition_metric: 0.7720\n",
      "\n",
      "Epoch 00016: val_competition_metric improved from 0.76930 to 0.77200, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 17/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0543 - acc: 0.7023 - competition_metric: 0.8584 - val_loss: 0.2242 - val_acc: 0.6812 - val_competition_metric: 0.7678\n",
      "\n",
      "Epoch 00017: val_competition_metric did not improve from 0.77200\n",
      "Epoch 18/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0501 - acc: 0.7011 - competition_metric: 0.8648 - val_loss: 0.2375 - val_acc: 0.6819 - val_competition_metric: 0.7701\n",
      "\n",
      "Epoch 00018: val_competition_metric did not improve from 0.77200\n",
      "Epoch 19/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0475 - acc: 0.6989 - competition_metric: 0.8702 - val_loss: 0.2351 - val_acc: 0.6906 - val_competition_metric: 0.7714\n",
      "\n",
      "Epoch 00019: val_competition_metric did not improve from 0.77200\n",
      "Epoch 20/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0477 - acc: 0.6960 - competition_metric: 0.8616 - val_loss: 0.2376 - val_acc: 0.6867 - val_competition_metric: 0.7727\n",
      "\n",
      "Epoch 00020: val_competition_metric improved from 0.77200 to 0.77270, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 21/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0476 - acc: 0.6893 - competition_metric: 0.8711 - val_loss: 0.2332 - val_acc: 0.6763 - val_competition_metric: 0.7779\n",
      "\n",
      "Epoch 00021: val_competition_metric improved from 0.77270 to 0.77790, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 22/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0440 - acc: 0.6888 - competition_metric: 0.8757 - val_loss: 0.2417 - val_acc: 0.6830 - val_competition_metric: 0.7720\n",
      "\n",
      "Epoch 00022: val_competition_metric did not improve from 0.77790\n",
      "Epoch 23/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0420 - acc: 0.6870 - competition_metric: 0.8797 - val_loss: 0.2476 - val_acc: 0.6625 - val_competition_metric: 0.7807\n",
      "\n",
      "Epoch 00023: val_competition_metric improved from 0.77790 to 0.78070, saving model to 3_origina_model_weights_fold_1.hdf5\n",
      "Epoch 24/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0428 - acc: 0.6794 - competition_metric: 0.8746 - val_loss: 0.2462 - val_acc: 0.6700 - val_competition_metric: 0.7722\n",
      "\n",
      "Epoch 00024: val_competition_metric did not improve from 0.78070\n",
      "Epoch 25/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0414 - acc: 0.6779 - competition_metric: 0.8812 - val_loss: 0.2492 - val_acc: 0.6528 - val_competition_metric: 0.7745\n",
      "\n",
      "Epoch 00025: val_competition_metric did not improve from 0.78070\n",
      "Epoch 26/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0419 - acc: 0.6782 - competition_metric: 0.8814 - val_loss: 0.2492 - val_acc: 0.6531 - val_competition_metric: 0.7667\n",
      "\n",
      "Epoch 00026: val_competition_metric did not improve from 0.78070\n",
      "Epoch 27/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0428 - acc: 0.6742 - competition_metric: 0.8776 - val_loss: 0.2551 - val_acc: 0.6692 - val_competition_metric: 0.7607\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 00027: val_competition_metric did not improve from 0.78070\n",
      "Epoch 28/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0386 - acc: 0.6704 - competition_metric: 0.8895 - val_loss: 0.2516 - val_acc: 0.6494 - val_competition_metric: 0.7724\n",
      "\n",
      "Epoch 00028: val_competition_metric did not improve from 0.78070\n",
      "Epoch 29/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0379 - acc: 0.6693 - competition_metric: 0.8839 - val_loss: 0.2545 - val_acc: 0.6450 - val_competition_metric: 0.7751\n",
      "\n",
      "Epoch 00029: val_competition_metric did not improve from 0.78070\n",
      "Epoch 30/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0372 - acc: 0.6707 - competition_metric: 0.8897 - val_loss: 0.2591 - val_acc: 0.6540 - val_competition_metric: 0.7753\n",
      "\n",
      "Epoch 00030: val_competition_metric did not improve from 0.78070\n",
      "Epoch 31/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0373 - acc: 0.6702 - competition_metric: 0.8836 - val_loss: 0.2593 - val_acc: 0.6546 - val_competition_metric: 0.7745\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\n",
      "Epoch 00031: val_competition_metric did not improve from 0.78070\n",
      "Epoch 32/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0356 - acc: 0.6696 - competition_metric: 0.8911 - val_loss: 0.2604 - val_acc: 0.6504 - val_competition_metric: 0.7752\n",
      "\n",
      "Epoch 00032: val_competition_metric did not improve from 0.78070\n",
      "Epoch 33/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0359 - acc: 0.6691 - competition_metric: 0.8917 - val_loss: 0.2607 - val_acc: 0.6501 - val_competition_metric: 0.7749\n",
      "\n",
      "Epoch 00033: val_competition_metric did not improve from 0.78070\n",
      "Epoch 34/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0361 - acc: 0.6703 - competition_metric: 0.8930 - val_loss: 0.2601 - val_acc: 0.6463 - val_competition_metric: 0.7774\n",
      "\n",
      "Epoch 00034: val_competition_metric did not improve from 0.78070\n",
      "Epoch 35/10000\n",
      "188/188 [==============================] - 74s 394ms/step - loss: 0.0353 - acc: 0.6690 - competition_metric: 0.8871 - val_loss: 0.2598 - val_acc: 0.6444 - val_competition_metric: 0.7769\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 00035: val_competition_metric did not improve from 0.78070\n",
      "Epoch 36/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0344 - acc: 0.6690 - competition_metric: 0.8912 - val_loss: 0.2593 - val_acc: 0.6482 - val_competition_metric: 0.7759\n",
      "\n",
      "Epoch 00036: val_competition_metric did not improve from 0.78070\n",
      "Epoch 37/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0358 - acc: 0.6701 - competition_metric: 0.8888 - val_loss: 0.2588 - val_acc: 0.6525 - val_competition_metric: 0.7764\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\n",
      "Epoch 00039: val_competition_metric did not improve from 0.78070\n",
      "Epoch 40/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0351 - acc: 0.6682 - competition_metric: 0.8909 - val_loss: 0.2596 - val_acc: 0.6523 - val_competition_metric: 0.7763\n",
      "\n",
      "Epoch 00040: val_competition_metric did not improve from 0.78070\n",
      "Epoch 41/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0353 - acc: 0.6686 - competition_metric: 0.8903 - val_loss: 0.2589 - val_acc: 0.6524 - val_competition_metric: 0.7750\n",
      "\n",
      "Epoch 00041: val_competition_metric did not improve from 0.78070\n",
      "Epoch 42/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0352 - acc: 0.6692 - competition_metric: 0.8867 - val_loss: 0.2584 - val_acc: 0.6514 - val_competition_metric: 0.7769\n",
      "\n",
      "Epoch 00042: val_competition_metric did not improve from 0.78070\n",
      "Epoch 43/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0352 - acc: 0.6681 - competition_metric: 0.8914 - val_loss: 0.2585 - val_acc: 0.6506 - val_competition_metric: 0.7767\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "\n",
      "Epoch 00043: val_competition_metric did not improve from 0.78070\n",
      "Epoch 00043: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 20000\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "input_1 = 128\n",
    "input_2 = 128\n",
    "for fold_number in [0,1]:\n",
    "    print ( 50*'-', ' FOLD ' + str(fold_number), 50*'-' )\n",
    "    ids_train = df.ids_train_batch[df.fold != fold_number]\n",
    "    ids_valid = df.ids_train_batch[df.fold == fold_number]\n",
    "\n",
    "    model = Unet(backbone_name='resnet34', encoder_weights=None,input_shape=(256,256,3),freeze_encoder=False,\n",
    "                            decoder_use_batchnorm = True,decoder_block_type = 'upsampling')\n",
    "    model.compile(optimizers.Adam(lr = 0.0001), bce_dice_loss, ['accuracy',competition_metric])\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_competition_metric',\n",
    "                               patience=20,\n",
    "                               verbose=1,\n",
    "                               min_delta=1e-12,\n",
    "                               mode='max'),\n",
    "                 ReduceLROnPlateau(monitor='val_competition_metric',\n",
    "                                   factor=0.2,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   epsilon=1e-12,\n",
    "                                   mode='max'),\n",
    "                 ModelCheckpoint(monitor='val_competition_metric',\n",
    "                                 filepath='3_origina_model_weights_fold_{}.hdf5'.format(fold_number),\n",
    "                                 save_best_only=True,verbose = 1,\n",
    "                                 mode='max')]\n",
    "    print('number of train samples in fold ' +str(fold_number) + ' is ' + str(len(ids_train)))\n",
    "    print('number of validation samples in fold ' +str(fold_number) + ' is ' + str(len(ids_valid)))\n",
    "    \n",
    "    model.load_weights('1_origina_model_weights_fold_{}.hdf5'.format(fold_number))\n",
    "    #model.load_weights('AUTOENCODER.hdf5'.format(fold_number))\n",
    "    model.fit_generator(generator=train_generator(ids_train),\n",
    "                        steps_per_epoch=np.ceil(float(len(ids_train)) / float(BATCH_SIZE)),\n",
    "                        epochs=10000,\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=valid_generator(ids_valid),\n",
    "                        validation_steps=np.ceil(float(len(ids_valid)) / float(BATCH_SIZE)))\n",
    "    \n",
    "    del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------  FOLD 0 --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n01z3/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train samples in fold 0 is 3000\n",
      "number of validation samples in fold 0 is 1000\n",
      "Epoch 1/10000\n",
      "188/188 [==============================] - 132s 705ms/step - loss: 0.3289 - acc: 0.7198 - competition_metric: 0.5200 - val_loss: 0.2788 - val_acc: 0.6975 - val_competition_metric: 0.6061\n",
      "\n",
      "Epoch 00001: val_competition_metric improved from -inf to 0.60610, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 2/10000\n",
      "188/188 [==============================] - 73s 390ms/step - loss: 0.2595 - acc: 0.7263 - competition_metric: 0.6313 - val_loss: 0.2347 - val_acc: 0.7145 - val_competition_metric: 0.6557\n",
      "\n",
      "Epoch 00002: val_competition_metric improved from 0.60610 to 0.65570, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 3/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.2067 - acc: 0.7271 - competition_metric: 0.6852 - val_loss: 0.2585 - val_acc: 0.7355 - val_competition_metric: 0.6297\n",
      "\n",
      "Epoch 00003: val_competition_metric did not improve from 0.65570\n",
      "Epoch 4/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.1879 - acc: 0.7491 - competition_metric: 0.7075 - val_loss: 0.2492 - val_acc: 0.7243 - val_competition_metric: 0.6469\n",
      "\n",
      "Epoch 00004: val_competition_metric did not improve from 0.65570\n",
      "Epoch 5/10000\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.1663 - acc: 0.7394 - competition_metric: 0.7308 - val_loss: 0.2265 - val_acc: 0.7358 - val_competition_metric: 0.7048\n",
      "\n",
      "Epoch 00005: val_competition_metric improved from 0.65570 to 0.70480, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 6/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.1555 - acc: 0.7542 - competition_metric: 0.7459 - val_loss: 0.2396 - val_acc: 0.7176 - val_competition_metric: 0.6951\n",
      "\n",
      "Epoch 00006: val_competition_metric did not improve from 0.70480\n",
      "Epoch 7/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.1314 - acc: 0.7730 - competition_metric: 0.7715 - val_loss: 0.2237 - val_acc: 0.7558 - val_competition_metric: 0.7347\n",
      "\n",
      "Epoch 00007: val_competition_metric improved from 0.70480 to 0.73470, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 8/10000\n",
      "188/188 [==============================] - 75s 400ms/step - loss: 0.1181 - acc: 0.7664 - competition_metric: 0.7806 - val_loss: 0.2262 - val_acc: 0.7472 - val_competition_metric: 0.7181\n",
      "\n",
      "Epoch 00008: val_competition_metric did not improve from 0.73470\n",
      "Epoch 9/10000\n",
      "188/188 [==============================] - 75s 400ms/step - loss: 0.1105 - acc: 0.7463 - competition_metric: 0.7869 - val_loss: 0.2000 - val_acc: 0.7248 - val_competition_metric: 0.7319\n",
      "\n",
      "Epoch 00009: val_competition_metric did not improve from 0.73470\n",
      "Epoch 10/10000\n",
      "188/188 [==============================] - 76s 402ms/step - loss: 0.0955 - acc: 0.7557 - competition_metric: 0.8034 - val_loss: 0.2166 - val_acc: 0.8057 - val_competition_metric: 0.7378\n",
      "\n",
      "Epoch 00010: val_competition_metric improved from 0.73470 to 0.73780, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 11/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.1071 - acc: 0.7461 - competition_metric: 0.7918 - val_loss: 0.2787 - val_acc: 0.7339 - val_competition_metric: 0.7400\n",
      "\n",
      "Epoch 00011: val_competition_metric improved from 0.73780 to 0.74000, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 12/10000\n",
      "188/188 [==============================] - 74s 395ms/step - loss: 0.0872 - acc: 0.7530 - competition_metric: 0.8194 - val_loss: 0.2028 - val_acc: 0.7171 - val_competition_metric: 0.7419\n",
      "\n",
      "Epoch 00012: val_competition_metric improved from 0.74000 to 0.74190, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 13/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0782 - acc: 0.7688 - competition_metric: 0.8248 - val_loss: 0.2499 - val_acc: 0.7373 - val_competition_metric: 0.7572\n",
      "\n",
      "Epoch 00013: val_competition_metric improved from 0.74190 to 0.75720, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 14/10000\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.0822 - acc: 0.7526 - competition_metric: 0.8210 - val_loss: 0.2282 - val_acc: 0.7221 - val_competition_metric: 0.7490\n",
      "\n",
      "Epoch 00014: val_competition_metric did not improve from 0.75720\n",
      "Epoch 15/10000\n",
      "188/188 [==============================] - 75s 401ms/step - loss: 0.0728 - acc: 0.7764 - competition_metric: 0.8329 - val_loss: 0.2315 - val_acc: 0.7328 - val_competition_metric: 0.7652\n",
      "\n",
      "Epoch 00015: val_competition_metric improved from 0.75720 to 0.76520, saving model to 4_origina_model_weights_fold_0.hdf5\n",
      "Epoch 16/10000\n",
      "152/188 [=======================>......] - ETA: 12s - loss: 0.0827 - acc: 0.7662 - competition_metric: 0.8336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0341 - acc: 0.7272 - competition_metric: 0.8934 - val_loss: 0.2507 - val_acc: 0.7041 - val_competition_metric: 0.7948\n",
      "\n",
      "Epoch 00046: val_competition_metric did not improve from 0.79700\n",
      "Epoch 47/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0350 - acc: 0.7257 - competition_metric: 0.8906 - val_loss: 0.2501 - val_acc: 0.7082 - val_competition_metric: 0.7931\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\n",
      "Epoch 00047: val_competition_metric did not improve from 0.79700\n",
      "Epoch 48/10000\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.0345 - acc: 0.7275 - competition_metric: 0.8929 - val_loss: 0.2498 - val_acc: 0.7051 - val_competition_metric: 0.7925\n",
      "\n",
      "Epoch 00048: val_competition_metric did not improve from 0.79700\n",
      "Epoch 49/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0345 - acc: 0.7263 - competition_metric: 0.8928 - val_loss: 0.2493 - val_acc: 0.7057 - val_competition_metric: 0.7931\n",
      "\n",
      "Epoch 00049: val_competition_metric did not improve from 0.79700\n",
      "Epoch 50/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0349 - acc: 0.7274 - competition_metric: 0.8950 - val_loss: 0.2502 - val_acc: 0.7056 - val_competition_metric: 0.7921\n",
      "\n",
      "Epoch 00050: val_competition_metric did not improve from 0.79700\n",
      "Epoch 51/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0348 - acc: 0.7262 - competition_metric: 0.8933 - val_loss: 0.2499 - val_acc: 0.7046 - val_competition_metric: 0.7922\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "\n",
      "Epoch 00051: val_competition_metric did not improve from 0.79700\n",
      "Epoch 52/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0350 - acc: 0.7255 - competition_metric: 0.8953 - val_loss: 0.2498 - val_acc: 0.7060 - val_competition_metric: 0.7935\n",
      "\n",
      "Epoch 00052: val_competition_metric did not improve from 0.79700\n",
      "Epoch 53/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0340 - acc: 0.7265 - competition_metric: 0.8889 - val_loss: 0.2511 - val_acc: 0.7085 - val_competition_metric: 0.7940\n",
      "\n",
      "Epoch 00053: val_competition_metric did not improve from 0.79700\n",
      "Epoch 54/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0344 - acc: 0.7272 - competition_metric: 0.8903 - val_loss: 0.2498 - val_acc: 0.7100 - val_competition_metric: 0.7941\n",
      "\n",
      "Epoch 00054: val_competition_metric did not improve from 0.79700\n",
      "Epoch 55/10000\n",
      "188/188 [==============================] - 76s 406ms/step - loss: 0.0342 - acc: 0.7270 - competition_metric: 0.8880 - val_loss: 0.2504 - val_acc: 0.7047 - val_competition_metric: 0.7926\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "\n",
      "Epoch 00055: val_competition_metric did not improve from 0.79700\n",
      "Epoch 00055: early stopping\n",
      "--------------------------------------------------  FOLD 1 --------------------------------------------------\n",
      "number of train samples in fold 1 is 3000\n",
      "number of validation samples in fold 1 is 1000\n",
      "Epoch 1/10000\n",
      "188/188 [==============================] - 134s 711ms/step - loss: 0.3258 - acc: 0.6260 - competition_metric: 0.5721 - val_loss: 0.2542 - val_acc: 0.6446 - val_competition_metric: 0.6568\n",
      "\n",
      "Epoch 00001: val_competition_metric improved from -inf to 0.65680, saving model to 4_origina_model_weights_fold_1.hdf5\n",
      "Epoch 2/10000\n",
      "188/188 [==============================] - 74s 391ms/step - loss: 0.2338 - acc: 0.6566 - competition_metric: 0.6665 - val_loss: 0.3765 - val_acc: 0.6507 - val_competition_metric: 0.6177\n",
      "\n",
      "Epoch 00002: val_competition_metric did not improve from 0.65680\n",
      "Epoch 3/10000\n",
      "188/188 [==============================] - 75s 401ms/step - loss: 0.2022 - acc: 0.6641 - competition_metric: 0.6998 - val_loss: 0.2034 - val_acc: 0.6536 - val_competition_metric: 0.7182\n",
      "\n",
      "Epoch 00003: val_competition_metric improved from 0.65680 to 0.71820, saving model to 4_origina_model_weights_fold_1.hdf5\n",
      "Epoch 4/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.1810 - acc: 0.6680 - competition_metric: 0.7283 - val_loss: 0.2256 - val_acc: 0.6478 - val_competition_metric: 0.7062\n",
      "\n",
      "Epoch 00004: val_competition_metric did not improve from 0.71820\n",
      "Epoch 5/10000\n",
      "188/188 [==============================] - 75s 400ms/step - loss: 0.1518 - acc: 0.6924 - competition_metric: 0.7580 - val_loss: 0.2254 - val_acc: 0.7117 - val_competition_metric: 0.7104\n",
      "\n",
      "Epoch 00005: val_competition_metric did not improve from 0.71820\n",
      "Epoch 6/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.1239 - acc: 0.6915 - competition_metric: 0.7694 - val_loss: 0.2431 - val_acc: 0.6616 - val_competition_metric: 0.7273\n",
      "\n",
      "Epoch 00006: val_competition_metric improved from 0.71820 to 0.72730, saving model to 4_origina_model_weights_fold_1.hdf5\n",
      "Epoch 7/10000\n",
      " 46/188 [======>.......................] - ETA: 49s - loss: 0.1261 - acc: 0.7075 - competition_metric: 0.7904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_competition_metric did not improve from 0.78870\n",
      "Epoch 33/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0391 - acc: 0.6782 - competition_metric: 0.8835 - val_loss: 0.2364 - val_acc: 0.6501 - val_competition_metric: 0.7891\n",
      "\n",
      "Epoch 00033: val_competition_metric improved from 0.78870 to 0.78910, saving model to 4_origina_model_weights_fold_1.hdf5\n",
      "Epoch 34/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0393 - acc: 0.6784 - competition_metric: 0.8838 - val_loss: 0.2375 - val_acc: 0.6525 - val_competition_metric: 0.7856\n",
      "\n",
      "Epoch 00034: val_competition_metric did not improve from 0.78910\n",
      "Epoch 35/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0391 - acc: 0.6786 - competition_metric: 0.8855 - val_loss: 0.2385 - val_acc: 0.6514 - val_competition_metric: 0.7879\n",
      "\n",
      "Epoch 00035: val_competition_metric did not improve from 0.78910\n",
      "Epoch 36/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0379 - acc: 0.6776 - competition_metric: 0.8869 - val_loss: 0.2391 - val_acc: 0.6501 - val_competition_metric: 0.7901\n",
      "\n",
      "Epoch 00036: val_competition_metric improved from 0.78910 to 0.79010, saving model to 4_origina_model_weights_fold_1.hdf5\n",
      "Epoch 37/10000\n",
      "188/188 [==============================] - 74s 396ms/step - loss: 0.0374 - acc: 0.6769 - competition_metric: 0.8863 - val_loss: 0.2390 - val_acc: 0.6492 - val_competition_metric: 0.7905\n",
      "\n",
      "Epoch 00037: val_competition_metric improved from 0.79010 to 0.79050, saving model to 4_origina_model_weights_fold_1.hdf5\n",
      "Epoch 38/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0375 - acc: 0.6769 - competition_metric: 0.8884 - val_loss: 0.2394 - val_acc: 0.6543 - val_competition_metric: 0.7889\n",
      "\n",
      "Epoch 00038: val_competition_metric did not improve from 0.79050\n",
      "Epoch 39/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0384 - acc: 0.6761 - competition_metric: 0.8828 - val_loss: 0.2410 - val_acc: 0.6487 - val_competition_metric: 0.7903\n",
      "\n",
      "Epoch 00039: val_competition_metric did not improve from 0.79050\n",
      "Epoch 40/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0381 - acc: 0.6756 - competition_metric: 0.8802 - val_loss: 0.2408 - val_acc: 0.6469 - val_competition_metric: 0.7904\n",
      "\n",
      "Epoch 00040: val_competition_metric did not improve from 0.79050\n",
      "Epoch 41/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0390 - acc: 0.6748 - competition_metric: 0.8878 - val_loss: 0.2401 - val_acc: 0.6491 - val_competition_metric: 0.7885\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 00041: val_competition_metric did not improve from 0.79050\n",
      "Epoch 42/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0371 - acc: 0.6754 - competition_metric: 0.8861 - val_loss: 0.2395 - val_acc: 0.6507 - val_competition_metric: 0.7916\n",
      "\n",
      "Epoch 00042: val_competition_metric improved from 0.79050 to 0.79160, saving model to 4_origina_model_weights_fold_1.hdf5\n",
      "Epoch 43/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0381 - acc: 0.6758 - competition_metric: 0.8808 - val_loss: 0.2397 - val_acc: 0.6467 - val_competition_metric: 0.7857\n",
      "\n",
      "Epoch 00043: val_competition_metric did not improve from 0.79160\n",
      "Epoch 44/10000\n",
      "188/188 [==============================] - 75s 396ms/step - loss: 0.0381 - acc: 0.6747 - competition_metric: 0.8870 - val_loss: 0.2383 - val_acc: 0.6455 - val_competition_metric: 0.7869\n",
      "\n",
      "Epoch 00044: val_competition_metric did not improve from 0.79160\n",
      "Epoch 45/10000\n",
      "188/188 [==============================] - 75s 398ms/step - loss: 0.0393 - acc: 0.6748 - competition_metric: 0.8853 - val_loss: 0.2388 - val_acc: 0.6500 - val_competition_metric: 0.7872\n",
      "\n",
      "Epoch 00045: val_competition_metric did not improve from 0.79160\n",
      "Epoch 46/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0379 - acc: 0.6748 - competition_metric: 0.8868 - val_loss: 0.2401 - val_acc: 0.6508 - val_competition_metric: 0.7847\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\n",
      "Epoch 00046: val_competition_metric did not improve from 0.79160\n",
      "Epoch 47/10000\n",
      "188/188 [==============================] - 75s 397ms/step - loss: 0.0378 - acc: 0.6748 - competition_metric: 0.8841 - val_loss: 0.2399 - val_acc: 0.6467 - val_competition_metric: 0.7851\n",
      "\n",
      "Epoch 00047: val_competition_metric did not improve from 0.79160\n",
      "Epoch 48/10000\n",
      "160/188 [========================>.....] - ETA: 9s - loss: 0.0375 - acc: 0.6755 - competition_metric: 0.8866 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 20000\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "input_1 = 128\n",
    "input_2 = 128\n",
    "for fold_number in [0,1]:\n",
    "    print ( 50*'-', ' FOLD ' + str(fold_number), 50*'-' )\n",
    "    ids_train = df.ids_train_batch[df.fold != fold_number]\n",
    "    ids_valid = df.ids_train_batch[df.fold == fold_number]\n",
    "\n",
    "    model = Unet(backbone_name='resnet34', encoder_weights=None,input_shape=(256,256,3),freeze_encoder=False,\n",
    "                            decoder_use_batchnorm = True,decoder_block_type = 'upsampling')\n",
    "    model.compile(optimizers.Adam(lr = 0.0001), bce_dice_loss, ['accuracy',competition_metric])\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_competition_metric',\n",
    "                               patience=20,\n",
    "                               verbose=1,\n",
    "                               min_delta=1e-12,\n",
    "                               mode='max'),\n",
    "                 ReduceLROnPlateau(monitor='val_competition_metric',\n",
    "                                   factor=0.2,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   epsilon=1e-12,\n",
    "                                   mode='max'),\n",
    "                 ModelCheckpoint(monitor='val_competition_metric',\n",
    "                                 filepath='4_origina_model_weights_fold_{}.hdf5'.format(fold_number),\n",
    "                                 save_best_only=True,verbose = 1,\n",
    "                                 mode='max')]\n",
    "    print('number of train samples in fold ' +str(fold_number) + ' is ' + str(len(ids_train)))\n",
    "    print('number of validation samples in fold ' +str(fold_number) + ' is ' + str(len(ids_valid)))\n",
    "    \n",
    "    model.load_weights('1_origina_model_weights_fold_{}.hdf5'.format(fold_number))\n",
    "    #model.load_weights('AUTOENCODER.hdf5'.format(fold_number))\n",
    "    model.fit_generator(generator=train_generator(ids_train),\n",
    "                        steps_per_epoch=np.ceil(float(len(ids_train)) / float(BATCH_SIZE)),\n",
    "                        epochs=10000,\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=valid_generator(ids_valid),\n",
    "                        validation_steps=np.ceil(float(len(ids_valid)) / float(BATCH_SIZE)))\n",
    "    \n",
    "    del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
