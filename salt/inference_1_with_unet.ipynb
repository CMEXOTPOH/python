{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from tta_wrapper_venheads import tta_segmentation\n",
    "import cv2\n",
    "from segmentation_models import Unet\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, BatchNormalization, Activation, UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from skimage.io import imread\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from tqdm import tqdm\n",
    "from keras import optimizers\n",
    "from losses_original import (\n",
    "    binary_crossentropy,\n",
    "    dice_loss,\n",
    "    bce_dice_loss,\n",
    "    dice_coef,\n",
    "    weighted_bce_dice_loss,my_iou_metric,\n",
    "    my_iou_metric_2,IOU_Metric_new,my_iou_metric_bowl,\n",
    "    competition_metric,\n",
    "    iou_bce_loss,lovasz_loss\n",
    ")\n",
    "\n",
    "number_folds = 5\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/ssd1/dataset/salt/sample_submission.csv')\n",
    "weg_train_img = '/mnt/ssd1/dataset/salt/images-test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pad(img, pad_size=256, mode=3):\n",
    "    x1 = (pad_size - img.shape[0]) // 2\n",
    "    x2 = pad_size - img.shape[0] - x1\n",
    "\n",
    "    if mode == 0:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, x1, x2, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    if mode == 1:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, x1, x2, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    if mode == 2:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, x1, x2, cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    if mode == 3:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, 0, 0, cv2.BORDER_REPLICATE)\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, x1, x2, cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    if mode == 4:\n",
    "        img = cv2.copyMakeBorder(img, x1, x2, 0, 0, cv2.BORDER_REFLECT_101)\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, x1, x2, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 77\n",
    "load_img = lambda im: np.pad(cv2.imread(join(weg_train_img, '{}.png'.format(im))) #[:,:,0:1]\\\n",
    ", ((pad,pad+1),(pad,pad+1),(0,0)), 'constant')\n",
    "load_mask = lambda im: np.pad(cv2.imread(join(weg_train_mask, '{}.png'.format(im)))[:,:,0]\\\n",
    "                              , ((pad,pad+1),(pad,pad+1)), 'constant')\n",
    "\n",
    "load_img = lambda im: custom_pad(cv2.imread(join(weg_train_img, '{}.png'.format(im))))\n",
    "load_mask = lambda im: custom_pad(cv2.imread(join(weg_train_mask, '{}.png'.format(im)))[:,:,0])\\\n",
    "\n",
    "test_ids = df.id.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weg = 'predictions'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [05:55<00:00, 50.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for fold 0\n",
      "FOLD 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [06:18<00:00, 47.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for fold 1\n",
      "FOLD 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [06:24<00:00, 46.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for fold 2\n",
      "FOLD 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [06:31<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for fold 3\n",
      "FOLD 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [06:34<00:00, 45.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for fold 0\n",
      "FOLD 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [06:38<00:00, 45.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for fold 1\n",
      "FOLD 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [06:42<00:00, 44.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for fold 2\n",
      "FOLD 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 9661/18000 [03:39<03:09, 43.98it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 18000/18000 [07:02<00:00, 42.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for fold 1\n",
      "FOLD 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1946/18000 [00:47<06:35, 40.63it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 47%|████▋     | 8411/18000 [03:23<03:51, 41.33it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for part in range(2,5):\n",
    "    for fold in range(4):\n",
    "        print ('FOLD ' + str(fold))\n",
    "        model = Unet(backbone_name='resnet34', encoder_weights='imagenet',input_shape=(256,256,3),\n",
    "                            decoder_use_batchnorm = True,decoder_block_type = 'upsampling')\n",
    "        model.compile(optimizers.Adam(lr = 0.0001), bce_dice_loss, ['accuracy',competition_metric])\n",
    "        model.load_weights('{}_origina_model_weights_fold_{}.hdf5'.format(part,fold))\n",
    "        #tta_model = tta_segmentation(model, h_flip=True, \n",
    "         #                    h_shifts=(-10, 10),v_shifts=(-10,10), merge='mean')\n",
    "\n",
    "        if not os.path.exists(weg+'{}_model_weights_fold_{}'.format(part,fold)): \n",
    "            os.mkdir(weg+'{}_model_weights_fold_{}'.format(part,fold))\n",
    "        for test_id in tqdm(test_ids,miniters=1000):\n",
    "            test_img =  load_img(test_id)/255.\n",
    "            test_img = np.expand_dims(test_img,0)\n",
    "            pred = model.predict(test_img)[0,77:-78,77:-78]\n",
    "            np.savez_compressed(weg+'{}_model_weights_fold_{}/'.format(part,fold) + test_id,pred)\n",
    "        print ('Saved for fold '+ str(fold))\n",
    "        del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(im):\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def filter_image(img):\n",
    "    if img.sum() < 100:\n",
    "        return np.zeros(img.shape)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [04:50<00:00, 62.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission file...\n",
      "finished_fold_3\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.47\n",
    "for x in [0]:\n",
    "    ids_test = test_ids\n",
    "\n",
    "\n",
    "\n",
    "    def _mask_to_rle_string(mask):\n",
    "        \"\"\"Convert boolean/`binary uint` mask to RLE string.\"\"\"\n",
    "        # Mask to RLE\n",
    "        pixels = mask.flatten()\n",
    "        pixels[0] = 0\n",
    "        pixels[-1] = 0\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "        runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "\n",
    "        # RLE to string\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "\n",
    "    names = []\n",
    "    for id in ids_test:\n",
    "        names.append('{}'.format(id))\n",
    "\n",
    "\n",
    "    rles = []\n",
    "\n",
    "    for id_1 in tqdm(ids_test,miniters=1000):\n",
    "        placeholder = np.ones((101,101,1))\n",
    "        for fold in range(4):\n",
    "            placeholder_2 = np.ones((101,101,1))\n",
    "            for part in range(2,5):\n",
    "                loaded = np.load(weg+'{}_model_weights_fold_{}/'.format(part,fold) + str(id_1)+'.npz')['arr_0']\n",
    "                placeholder_2*=loaded\n",
    "            placeholder_2 = np.power(placeholder_2,1./3)\n",
    "            prob = placeholder_2#[13:-14,13:-14,:]\n",
    "            placeholder*=prob\n",
    "        placeholder = np.power(placeholder,1./4)    \n",
    "        mask = placeholder > threshold\n",
    "        #rle = _mask_to_rle_string(mask)\n",
    "        #rle = rle_encode(filter_image(mask))\n",
    "        rle = rle_encode(mask)\n",
    "        if len(rle.split(' ')) < 5:\n",
    "            rle = ''\n",
    "        rles.append(rle)\n",
    "\n",
    "    print(\"Generating submission file...\")\n",
    "    df = pd.DataFrame({'id': names, 'rle_mask': rles})\n",
    "    df.to_csv('submit/fold_'+str(fold)+'densenet169.csv.gz', index=False, compression='gzip')\n",
    "    print('finished_fold_' + str(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1771/18000 [00:35<05:22, 50.33it/s]"
     ]
    }
   ],
   "source": [
    "ids_test = test_ids\n",
    "for id_1 in tqdm(ids_test,miniters=1000):\n",
    "    placeholder = np.ones((101,101,1))\n",
    "    for fold in range(4):\n",
    "        placeholder_2 = np.ones((101,101,1))\n",
    "        for part in range(2,5):\n",
    "            loaded = np.load(weg+'{}_model_weights_fold_{}/'.format(part,fold) + str(id_1)+'.npz')['arr_0']\n",
    "            placeholder_2*=loaded\n",
    "        placeholder_2 = np.power(placeholder_2,1./3)\n",
    "        prob = placeholder_2#[13:-14,13:-14,:]\n",
    "        placeholder*=prob\n",
    "    placeholder = np.power(placeholder,1./5)    \n",
    "    np.savez_compressed('total_geom_avg/{}'.format(id_1),placeholder)\n",
    "    cv2.imwrite(\"total_geom_avg/{}.png\".format(id_1), placeholder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
