{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "weg = '/media/n01z3/storage3/datasets/carvana/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renorm import BatchRenormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "white = False\n",
    "def img_gen(x):\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,rescale = x,vertical_flip = False,\n",
    "        horizontal_flip=True,\n",
    "        zca_whitening=white)\n",
    "    return image_generator\n",
    "\n",
    "mask_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,rescale = None,vertical_flip = False,\n",
    "    horizontal_flip=True,\n",
    "    zca_whitening=white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_img = lambda im: cv2.imread(join(weg+'train', '{}.jpg'.format(im)))\n",
    "load_mask = lambda im: imread(join(weg+'train_masks', '{}_mask.gif'.format(im)))\n",
    "load_mask_gif = lambda im: imread(join(weg+'train_masks', '{}_mask.gif'.format(im)))[:,:,0]\n",
    "\n",
    "resize = lambda im: downscale_local_mean(im, (4,4) if im.ndim==2 else (4,4,1))\n",
    "mask_image = lambda im, mask: (im * np.expand_dims(mask, 2))\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_gen(size=1,height=160,width=240,aug=True,inter=True,fit=False):\n",
    "    counter = 0 #счетчик запускам\n",
    "    global fold_number\n",
    "    select = df_folds.img.values[df_folds.fold!=fold_number]\n",
    "    number_of_batches = np.ceil(len(select)/size) #количестов партий - зависит от размера партии\n",
    "    while 1:\n",
    "\n",
    "        scale_factor = np.random.randint(80,120)/100.\n",
    "        image_generator = img_gen(scale_factor)\n",
    "\n",
    "\n",
    "        cc = 0\n",
    "        x = np.empty((size, height, width, 3), dtype=np.float32) # пустой массив для загрузки картинок\n",
    "        y = np.empty((size, height, width, 1), dtype=np.float32)\n",
    "        for img_id in select[size*counter:size*(counter+1)]: #16\n",
    "\n",
    "            imgs_id = [cv2.resize(load_img(img_id),(width,height))/255.]\n",
    "\n",
    "           \n",
    "            mask_16 = [cv2.resize(load_mask(img_id), ( width,height))/ 255.]\n",
    "            try:\n",
    "                if mask_16[0].shape[2]>1:\n",
    "\n",
    "                    mask_16 = [cv2.resize(load_mask_gif(img_id), ( width,height))/ 255.]\n",
    "            except:\n",
    "                pass\n",
    "                            \n",
    "            x[cc:(1+cc)] = np.array(imgs_id)\n",
    "            y[cc:(1+cc)] = np.expand_dims(np.array(mask_16),3)\n",
    "            \n",
    "            cc+=1    \n",
    "        del imgs_id\n",
    "        counter+=1\n",
    "        SEED = int(np.random.randint(0,999999,1))\n",
    "        if inter == False: #если не чередуем данные\n",
    "            if aug == True:  # делаем ли аугментацию?\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "\n",
    "\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "\n",
    "            if aug == False: # или базовую картинку?\n",
    "                yield(x,y)\n",
    "\n",
    "        if inter == True: # если чередуем то по очереди загружаем то одно то другое\n",
    "            if counter % 2 ==0:\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "\n",
    "            else:\n",
    "                yield(x,y)\n",
    "                \n",
    "        if counter == number_of_batches:\n",
    "            counter = 0\n",
    "            np.random.shuffle(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_gen(size=1,height=160,width=240,aug=True,inter = True,fit=False):\n",
    "    global fold_number\n",
    "    select = df_folds.img.values[df_folds.fold==fold_number]\n",
    "    number_of_batches = np.ceil(len(select)/size) #количестов партий - зависит от размера партии\n",
    "    counter = 0\n",
    "    while 1:\n",
    "\n",
    "\n",
    "\n",
    "        cc = 0\n",
    "        x = np.empty((size, height, width, 3), dtype=np.float32) # пустой массив для загрузки картинок\n",
    "        y = np.empty((size, height, width, 1), dtype=np.float32)\n",
    "        for img_id in select[size*counter:size*(counter+1)]: #16\n",
    "\n",
    "            imgs_id = [cv2.resize(load_img(img_id),(width,height))/255.]\n",
    "            # Input is image + mean image per channel + std image per channel\n",
    "            mask_16 = [cv2.resize(load_mask(img_id), ( width,height))/ 255.]\n",
    "            try:\n",
    "                if mask_16[0].shape[2]>1:\n",
    "\n",
    "                    mask_16 = [cv2.resize(load_mask_gif(img_id), ( width,height))/ 255.]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            x[cc:(1+cc)] = np.array(imgs_id)\n",
    "            y[cc:(1+cc)] = np.expand_dims(np.array(mask_16),3)\n",
    "            \n",
    "            cc+=1    \n",
    "        del imgs_id\n",
    "        counter+=1\n",
    "        \n",
    "        SEED = int(np.random.randint(0,999999,1))\n",
    "        if inter == False: #если не чередуем данные\n",
    "            if aug == True:  # делаем ли аугментацию?\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "\n",
    "\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "                #del img,msk\n",
    "                #del x,y\n",
    "            if aug == False: # или базовую картинку?\n",
    "                yield(x,y)\n",
    "                #del x,y\n",
    "        if inter == True: # если чередуем то по очереди загружаем то одно то другое\n",
    "            if counter % 2 ==0:\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "                \n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "                #del img,msk\n",
    "                #del x,y\n",
    "            else:\n",
    "                yield(x,y)\n",
    "                #del x,y\n",
    "        \n",
    "        if counter == number_of_batches:\n",
    "            counter = 0\n",
    "            np.random.shuffle(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, BatchNormalization, Activation, UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_unet_1024(input_shape=(1280, 1280, 3),\n",
    "                 num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 512\n",
    "\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(inputs)\n",
    "    down0a = BatchRenormalization()(down0a)\n",
    "    down0a = ELU()(down0a)\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(down0a)\n",
    "    down0a = BatchRenormalization()(down0a)\n",
    "    down0a = ELU()(down0a)\n",
    "    down0a_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0a)\n",
    "    # 256\n",
    "\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0a_pool)\n",
    "    down0 = BatchRenormalization()(down0)\n",
    "    down0 = ELU()(down0)\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchRenormalization()(down0)\n",
    "    down0 = ELU()(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchRenormalization()(down1)\n",
    "    down1 = ELU()(down1)\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchRenormalization()(down1)\n",
    "    down1 = ELU()(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchRenormalization()(down2)\n",
    "    down2 = ELU()(down2)\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchRenormalization()(down2)\n",
    "    down2 = ELU()(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchRenormalization()(down3)\n",
    "    down3 = ELU()(down3)\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchRenormalization()(down3)\n",
    "    down3 = ELU()(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "    # 16\n",
    "\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n",
    "    down4 = BatchRenormalization()(down4)\n",
    "    down4 = ELU()(down4)\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n",
    "    down4 = BatchRenormalization()(down4)\n",
    "    down4 = ELU()(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "    # 8\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n",
    "    center = BatchRenormalization()(center)\n",
    "    center = ELU()(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchRenormalization()(center)\n",
    "    center = ELU()(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down4, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down3, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    # 128\n",
    "\n",
    "    up0 = UpSampling2D((2, 2))(up1)\n",
    "    up0 = concatenate([down0, up0], axis=3)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    # 256\n",
    "\n",
    "    up0a = UpSampling2D((2, 2))(up0)\n",
    "    up0a = concatenate([down0a, up0a], axis=3)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    # 512\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up0a)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss=dice_coef_loss, metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss=dice_coef_loss, metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='binary_crossentropy', metrics=[dice_loss,'accuracy'])\n",
    "    #SGD(lr=0.01, momentum=0.9)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "df_folds = pd.read_csv(weg+'folds_ready.csv')\n",
    "df_train = pd.read_csv(weg+'train_masks.csv')\n",
    "ids_train = df_train['img'].map(lambda s: s.split('.')[0])\n",
    "\n",
    "input_size_1 = 1920\n",
    "input_size_2 = 1280\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "\n",
    "#ids_train_split, ids_valid_split = train_test_split(ids_train, test_size=0.1)#, random_state=42)\n",
    "\n",
    "#print('Training on {} samples'.format(len(ids_train_split)))\n",
    "#print('Validating on {} samples'.format(len(ids_valid_split)))\n",
    "\n",
    "\n",
    "def randomShiftScaleRotate(image, mask,\n",
    "                           shift_limit=(-0.0625, 0.0625),\n",
    "                           scale_limit=(-0.1, 0.1),\n",
    "                           rotate_limit=(-45, 45), aspect_limit=(0, 0),\n",
    "                           borderMode=cv2.BORDER_CONSTANT, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        height, width, channel = image.shape\n",
    "\n",
    "        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree\n",
    "        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "        sx = scale * aspect / (aspect ** 0.5)\n",
    "        sy = scale / (aspect ** 0.5)\n",
    "        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
    "        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
    "\n",
    "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "        box1 = box0 - np.array([width / 2, height / 2])\n",
    "        box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "        box0 = box0.astype(np.float32)\n",
    "        box1 = box1.astype(np.float32)\n",
    "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "        image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                    borderValue=(\n",
    "                                        0, 0,\n",
    "                                        0,))\n",
    "        mask = cv2.warpPerspective(mask, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                   borderValue=(\n",
    "                                       0, 0,\n",
    "                                       0,))\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def randomHorizontalFlip(image, mask, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def train_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(ids_train_split), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(ids_train_split))\n",
    "            ids_train_batch = ids_train_split[start:end]\n",
    "            for id in ids_train_batch.values:\n",
    "                img = cv2.imread(weg+'train/{}.jpg'.format(id))\n",
    "                img = cv2.resize(img, (input_size_1, input_size_2))\n",
    "                mask = imread(weg+'train_masks/{}_mask.gif'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "                try:\n",
    "                    if mask.shape[2]>1:\n",
    "\n",
    "                        mask = mask[:,:,0]\n",
    "                except:\n",
    "                    pass\n",
    "                mask = cv2.resize(mask, (input_size_1, input_size_2))\n",
    "                img, mask = randomShiftScaleRotate(img, mask,\n",
    "                                                   shift_limit=(-0.0625, 0.0625),\n",
    "                                                   scale_limit=(-0.1, 0.1),\n",
    "                                                   rotate_limit=(-0, 0))\n",
    "                img, mask = randomHorizontalFlip(img, mask)\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "\n",
    "def valid_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(ids_valid_split), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(ids_valid_split))\n",
    "            ids_valid_batch = ids_valid_split[start:end]\n",
    "            for id in ids_valid_batch.values:\n",
    "                img = cv2.imread(weg+'train/{}.jpg'.format(id))\n",
    "                img = cv2.resize(img, (input_size_1, input_size_2))\n",
    "                mask = imread(weg+'train_masks/{}_mask.gif'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "                try:\n",
    "                    if mask.shape[2]>1:\n",
    "\n",
    "                        mask = mask[:,:,0]\n",
    "                except:\n",
    "                    pass\n",
    "                mask = cv2.resize(mask, (input_size_1, input_size_2))\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "epochs = 100\n",
    "coef = 2\n",
    "batch_size = 1\n",
    "for fold_number in [1]:\n",
    "    print '----------------------------- FOLD ' + str(fold_number) + ' -----------------------------------' \n",
    "    train_gen_step_size = len(df_folds.img.values[df_folds.fold!=fold_number])\n",
    "    val_gen_step_size = len(df_folds.img.values[df_folds.fold==fold_number]) \n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=4,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=2,\n",
    "                               cooldown=2,\n",
    "                               verbose=1),\n",
    "             ModelCheckpoint(filepath=str(fold_number)+'_fold_1280_1280_ElU_renorm.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,verbose=1),\n",
    "             TensorBoard(log_dir='logs')]\n",
    "    \n",
    "    model = get_unet_1024()\n",
    "    print 'number of train samples in fold ' +str(fold_number) + ' is ' + str(train_gen_step_size)\n",
    "    print 'number of validation samples in fold ' +str(fold_number) + ' is ' + str(val_gen_step_size)\n",
    "    \n",
    "    model.load_weights(str(fold_number)+'_fold_1280_1280_ElU_renorm.hdf5')\n",
    "    model.fit_generator(generator=batch_gen(size=batch_size,height=1280,width=1280),\n",
    "        steps_per_epoch =coef * int(train_gen_step_size/(batch_size*1)),\n",
    "        validation_data = val_gen(size=1,aug=False,inter=False,height=1280,width=1280),\n",
    "        validation_steps=coef * int(val_gen_step_size/(batch_size*1)),\n",
    "        verbose=1,callbacks=callbacks,epochs =epochs)\n",
    "    \n",
    "    del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fold_number = 1\n",
    "model = get_unet_1024()\n",
    "model.load_weights(str(fold_number)+'_fold_1280_1280_ElU_renorm.hdf5')\n",
    "model.evaluate_generator(generator=\n",
    "          val_gen(size=1,aug=False,inter=False,height=1280,width=1280),\n",
    "steps=1 * int(val_gen_step_size/(batch_size*1))\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
