{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "weg = '/media/n01z3/storage3/dataset/carvana/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from renorm import BatchRenormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "white = False\n",
    "image_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    zca_whitening=white)\n",
    "\n",
    "mask_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    zca_whitening=white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_img = lambda im: cv2.imread(join(weg+'train', '{}.jpg'.format(im)))\n",
    "load_mask = lambda im: imread(join(weg+'train_masks', '{}_mask.gif'.format(im)))\n",
    "load_mask_gif = lambda im: imread(join(weg+'train_masks', '{}_mask.gif'.format(im)))[:,:,0]\n",
    "\n",
    "resize = lambda im: downscale_local_mean(im, (4,4) if im.ndim==2 else (4,4,1))\n",
    "mask_image = lambda im, mask: (im * np.expand_dims(mask, 2))\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_gen(size=1,height=160,width=240,aug=True,inter=True,fit=False):\n",
    "    counter = 0 #счетчик запускам\n",
    "    global fold_number\n",
    "    select = df_folds.img.values[df_folds.fold!=fold_number]\n",
    "    number_of_batches = np.ceil(len(select)/size) #количестов партий - зависит от размера партии\n",
    "    while 1:\n",
    "\n",
    "\n",
    "\n",
    "        cc = 0\n",
    "        x = np.empty((size, height, width, 3), dtype=np.float32) # пустой массив для загрузки картинок\n",
    "        y = np.empty((size, height, width, 1), dtype=np.float32)\n",
    "        for img_id in select[size*counter:size*(counter+1)]: #16\n",
    "\n",
    "            imgs_id = [cv2.resize(load_img(img_id),(width,height))/255.]\n",
    "            # Input is image + mean image per channel + std image per channel\n",
    "           \n",
    "            mask_16 = [cv2.resize(load_mask(img_id), ( width,height))/ 255.]\n",
    "            try:\n",
    "                if mask_16[0].shape[2]>1:\n",
    "\n",
    "                    mask_16 = [cv2.resize(load_mask_gif(img_id), ( width,height))/ 255.]\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            #X[i] = np.concatenate([imgs_id[idx-1], np.mean(imgs_id, axis=0), np.std(imgs_id, axis=0)], axis=2)\n",
    "            \n",
    "            x[cc:(1+cc)] = np.array(imgs_id)\n",
    "            y[cc:(1+cc)] = np.expand_dims(np.array(mask_16),3)\n",
    "            \n",
    "            cc+=1    \n",
    "        del imgs_id\n",
    "        counter+=1\n",
    "        SEED = int(np.random.randint(0,999999,1))\n",
    "        if inter == False: #если не чередуем данные\n",
    "            if aug == True:  # делаем ли аугментацию?\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "\n",
    "\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "\n",
    "            if aug == False: # или базовую картинку?\n",
    "                yield(x,y)\n",
    "\n",
    "        if inter == True: # если чередуем то по очереди загружаем то одно то другое\n",
    "            if counter % 2 ==0:\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "\n",
    "            else:\n",
    "                yield(x,y)\n",
    "                \n",
    "        if counter == number_of_batches:\n",
    "            counter = 0\n",
    "            np.random.shuffle(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_gen(size=1,height=160,width=240,aug=True,inter = True,fit=False):\n",
    "    global fold_number\n",
    "    select = df_folds.img.values[df_folds.fold==fold_number]\n",
    "    number_of_batches = np.ceil(len(select)/size) #количестов партий - зависит от размера партии\n",
    "    counter = 0\n",
    "    while 1:\n",
    "\n",
    "\n",
    "\n",
    "        cc = 0\n",
    "        x = np.empty((size, height, width, 3), dtype=np.float32) # пустой массив для загрузки картинок\n",
    "        y = np.empty((size, height, width, 1), dtype=np.float32)\n",
    "        for img_id in select[size*counter:size*(counter+1)]: #16\n",
    "\n",
    "            imgs_id = [cv2.resize(load_img(img_id),(width,height))/255.]\n",
    "            # Input is image + mean image per channel + std image per channel\n",
    "            mask_16 = [cv2.resize(load_mask(img_id), ( width,height))/ 255.]\n",
    "            try:\n",
    "                if mask_16[0].shape[2]>1:\n",
    "\n",
    "                    mask_16 = [cv2.resize(load_mask_gif(img_id), ( width,height))/ 255.]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            x[cc:(1+cc)] = np.array(imgs_id)\n",
    "            y[cc:(1+cc)] = np.expand_dims(np.array(mask_16),3)\n",
    "            \n",
    "            cc+=1    \n",
    "        del imgs_id\n",
    "        counter+=1\n",
    "        \n",
    "        SEED = int(np.random.randint(0,999999,1))\n",
    "        if inter == False: #если не чередуем данные\n",
    "            if aug == True:  # делаем ли аугментацию?\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "\n",
    "\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "                #del img,msk\n",
    "                #del x,y\n",
    "            if aug == False: # или базовую картинку?\n",
    "                yield(x,y)\n",
    "                #del x,y\n",
    "        if inter == True: # если чередуем то по очереди загружаем то одно то другое\n",
    "            if counter % 2 ==0:\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "                \n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "                #del img,msk\n",
    "                #del x,y\n",
    "            else:\n",
    "                yield(x,y)\n",
    "                #del x,y\n",
    "        \n",
    "        if counter == number_of_batches:\n",
    "            counter = 0\n",
    "            np.random.shuffle(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, BatchNormalization, Activation, UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_unet_1024(input_shape=(1280, 1280, 3),\n",
    "                 num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 512\n",
    "\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(inputs)\n",
    "    down0a = BatchRenormalization()(down0a)\n",
    "    down0a = ELU()(down0a)\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(down0a)\n",
    "    down0a = BatchRenormalization()(down0a)\n",
    "    down0a = ELU()(down0a)\n",
    "    down0a_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0a)\n",
    "    # 256\n",
    "\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0a_pool)\n",
    "    down0 = BatchRenormalization()(down0)\n",
    "    down0 = ELU()(down0)\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchRenormalization()(down0)\n",
    "    down0 = ELU()(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchRenormalization()(down1)\n",
    "    down1 = ELU()(down1)\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchRenormalization()(down1)\n",
    "    down1 = ELU()(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchRenormalization()(down2)\n",
    "    down2 = ELU()(down2)\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchRenormalization()(down2)\n",
    "    down2 = ELU()(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchRenormalization()(down3)\n",
    "    down3 = ELU()(down3)\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchRenormalization()(down3)\n",
    "    down3 = ELU()(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "    # 16\n",
    "\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n",
    "    down4 = BatchRenormalization()(down4)\n",
    "    down4 = ELU()(down4)\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n",
    "    down4 = BatchRenormalization()(down4)\n",
    "    down4 = ELU()(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "    # 8\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n",
    "    center = BatchRenormalization()(center)\n",
    "    center = ELU()(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchRenormalization()(center)\n",
    "    center = ELU()(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down4, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down3, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    # 128\n",
    "\n",
    "    up0 = UpSampling2D((2, 2))(up1)\n",
    "    up0 = concatenate([down0, up0], axis=3)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    # 256\n",
    "\n",
    "    up0a = UpSampling2D((2, 2))(up0)\n",
    "    up0a = concatenate([down0a, up0a], axis=3)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    # 512\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up0a)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss=dice_coef_loss, metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='binary_crossentropy', metrics=[dice_loss,'accuracy'])\n",
    "    #SGD(lr=0.01, momentum=0.9)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "df_folds = pd.read_csv(weg+'folds_ready.csv')\n",
    "df_train = pd.read_csv(weg+'train_masks.csv')\n",
    "ids_train = df_train['img'].map(lambda s: s.split('.')[0])\n",
    "\n",
    "input_size_1 = 1920\n",
    "input_size_2 = 1280\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "\n",
    "#ids_train_split, ids_valid_split = train_test_split(ids_train, test_size=0.1)#, random_state=42)\n",
    "\n",
    "#print('Training on {} samples'.format(len(ids_train_split)))\n",
    "#print('Validating on {} samples'.format(len(ids_valid_split)))\n",
    "\n",
    "\n",
    "def randomShiftScaleRotate(image, mask,\n",
    "                           shift_limit=(-0.0625, 0.0625),\n",
    "                           scale_limit=(-0.1, 0.1),\n",
    "                           rotate_limit=(-45, 45), aspect_limit=(0, 0),\n",
    "                           borderMode=cv2.BORDER_CONSTANT, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        height, width, channel = image.shape\n",
    "\n",
    "        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree\n",
    "        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "        sx = scale * aspect / (aspect ** 0.5)\n",
    "        sy = scale / (aspect ** 0.5)\n",
    "        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
    "        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
    "\n",
    "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "        box1 = box0 - np.array([width / 2, height / 2])\n",
    "        box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "        box0 = box0.astype(np.float32)\n",
    "        box1 = box1.astype(np.float32)\n",
    "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "        image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                    borderValue=(\n",
    "                                        0, 0,\n",
    "                                        0,))\n",
    "        mask = cv2.warpPerspective(mask, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                   borderValue=(\n",
    "                                       0, 0,\n",
    "                                       0,))\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def randomHorizontalFlip(image, mask, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def train_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(ids_train_split), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(ids_train_split))\n",
    "            ids_train_batch = ids_train_split[start:end]\n",
    "            for id in ids_train_batch.values:\n",
    "                img = cv2.imread(weg+'train/{}.jpg'.format(id))\n",
    "                img = cv2.resize(img, (input_size_1, input_size_2))\n",
    "                mask = imread(weg+'train_masks/{}_mask.gif'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "                try:\n",
    "                    if mask.shape[2]>1:\n",
    "\n",
    "                        mask = mask[:,:,0]\n",
    "                except:\n",
    "                    pass\n",
    "                mask = cv2.resize(mask, (input_size_1, input_size_2))\n",
    "                img, mask = randomShiftScaleRotate(img, mask,\n",
    "                                                   shift_limit=(-0.0625, 0.0625),\n",
    "                                                   scale_limit=(-0.1, 0.1),\n",
    "                                                   rotate_limit=(-0, 0))\n",
    "                img, mask = randomHorizontalFlip(img, mask)\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "\n",
    "def valid_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(ids_valid_split), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(ids_valid_split))\n",
    "            ids_valid_batch = ids_valid_split[start:end]\n",
    "            for id in ids_valid_batch.values:\n",
    "                img = cv2.imread(weg+'train/{}.jpg'.format(id))\n",
    "                img = cv2.resize(img, (input_size_1, input_size_2))\n",
    "                mask = imread(weg+'train_masks/{}_mask.gif'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "                try:\n",
    "                    if mask.shape[2]>1:\n",
    "\n",
    "                        mask = mask[:,:,0]\n",
    "                except:\n",
    "                    pass\n",
    "                mask = cv2.resize(mask, (input_size_1, input_size_2))\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tqdm import tqdm\n",
    "size_1 = 1280\n",
    "size_2 = 1280\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df_test = pd.read_csv(weg+'sample_submission.csv')\n",
    "ids_test = df_test['img'].map(lambda s: s.split('.')[0])\n",
    "for fold in [2,3]:\n",
    "    print 'FOLD ' + str(fold)\n",
    "    model = get_unet_1024()\n",
    "    model.load_weights(str(fold)+'_fold_1280_1280_ElU_renorm.hdf5')\n",
    "    for test_id in tqdm(ids_test.values,miniters=1000):\n",
    "        if not os.path.exists(weg+str(fold)+'_fold_test_predicted'): os.mkdir(weg+str(fold)+'_fold_test_predicted')\n",
    "        test_img =  cv2.resize(cv2.imread(weg+'test/{}.jpg'.format(test_id)),(size_1,size_2))/255.\n",
    "        test_img = np.expand_dims(test_img,0)\n",
    "        pred = model.predict(test_img)[0]\n",
    "        np.savez(weg+str(fold)+'_fold_test_predicted/' + test_id,pred)\n",
    "    print 'Saved for fold '+ str(fold)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100064/100064 [42:50<00:00, 38.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100064 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished_fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100064/100064 [1:13:55<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission file...\n",
      "finished_fold_4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "threshold = 0.5\n",
    "for fold in [3,4]:\n",
    "    df_test = pd.read_csv(weg+'sample_submission.csv')\n",
    "    ids_test = df_test['img'].map(lambda s: s.split('.')[0])\n",
    "\n",
    "\n",
    "    orig_width = 1918\n",
    "    orig_height = 1280\n",
    "\n",
    "    def _mask_to_rle_string(mask):\n",
    "        \"\"\"Convert boolean/`binary uint` mask to RLE string.\"\"\"\n",
    "        # Mask to RLE\n",
    "        pixels = mask.flatten()\n",
    "        pixels[0] = 0\n",
    "        pixels[-1] = 0\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "        runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "\n",
    "        # RLE to string\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "\n",
    "    names = []\n",
    "    for id in ids_test:\n",
    "        names.append('{}.jpg'.format(id))\n",
    "\n",
    "\n",
    "    rles = []\n",
    "\n",
    "    for id_1 in tqdm(ids_test,miniters=1000):\n",
    "\n",
    "        loaded = np.load(weg+str(fold)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']\n",
    "        prob = cv2.resize(loaded, (orig_width, orig_height))\n",
    "        mask = prob > threshold\n",
    "        rle = _mask_to_rle_string(mask)\n",
    "        rles.append(rle)\n",
    "\n",
    "    print(\"Generating submission file...\")\n",
    "    df = pd.DataFrame({'img': names, 'rle_mask': rles})\n",
    "    df.to_csv('submit/fold_'+str(fold)+'_test_precidted.csv.gz', index=False, compression='gzip')\n",
    "    print 'finished_fold_' + str(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100064/100064 [2:11:53<00:00, 10.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission file...\n",
      "finished_fold_1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "threshold = 0.5\n",
    "for fold in [1]:\n",
    "    df_test = pd.read_csv(weg+'sample_submission.csv')\n",
    "    ids_test = df_test['img'].map(lambda s: s.split('.')[0])\n",
    "\n",
    "\n",
    "    orig_width = 1918\n",
    "    orig_height = 1280\n",
    "\n",
    "    def _mask_to_rle_string(mask):\n",
    "        \"\"\"Convert boolean/`binary uint` mask to RLE string.\"\"\"\n",
    "        # Mask to RLE\n",
    "        pixels = mask.flatten()\n",
    "        pixels[0] = 0\n",
    "        pixels[-1] = 0\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "        runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "\n",
    "        # RLE to string\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "\n",
    "    names = []\n",
    "    for id in ids_test:\n",
    "        names.append('{}.jpg'.format(id))\n",
    "\n",
    "\n",
    "    rles = []\n",
    "\n",
    "    for id_1 in tqdm(ids_test,miniters=1000):\n",
    "\n",
    "        loaded = np.load(weg+str(fold)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']\n",
    "        prob = cv2.resize(loaded, (orig_width, orig_height))\n",
    "        mask = prob > threshold\n",
    "        rle = _mask_to_rle_string(mask)\n",
    "        rles.append(rle)\n",
    "\n",
    "    print(\"Generating submission file...\")\n",
    "    df = pd.DataFrame({'img': names, 'rle_mask': rles})\n",
    "    df.to_csv('submit/fold_'+str(fold)+'_test_precidted.csv.gz', index=False, compression='gzip')\n",
    "    print 'finished_fold_' + str(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded = np.load(weg+str(fold)+'_fold_test_predicted/' + str(id_1)+'.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "prob = cv2.resize(loaded, (orig_width, orig_height))\n",
    "mask = prob > threshold\n",
    "rle = _mask_to_rle_string(mask)\n",
    "rles.append(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(weg+'sample_submission.csv')\n",
    "ids_test = df_test['img'].map(lambda s: s.split('.')[0])\n",
    "\n",
    "\n",
    "orig_width = 1918\n",
    "orig_height = 1280\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "\n",
    "names = []\n",
    "for id in ids_test:\n",
    "    names.append('{}.jpg'.format(id))\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def run_length_encode(mask):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    inds = mask.flatten()\n",
    "    runs = np.where(inds[1:] != inds[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    rle = ' '.join([str(r) for r in runs])\n",
    "    return rle\n",
    "\n",
    "\n",
    "rles = []\n",
    "\n",
    "#test_splits = 8*59  # Split test set (number of splits must be multiple of 2)\n",
    "#ids_test_splits = np.split(ids_test, indices_or_sections=test_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _mask_to_rle_string(mask):\n",
    "    \"\"\"Convert boolean/`binary uint` mask to RLE string.\"\"\"\n",
    "    # Mask to RLE\n",
    "    pixels = mask.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "\n",
    "    # RLE to string\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_count = 0\n",
    "for ids_test_split in ids_test_splits:\n",
    "    split_count += 1\n",
    "\n",
    "\n",
    "    def test_generator():\n",
    "        while True:\n",
    "            for start in range(0, len(ids_test_split), batch_size):\n",
    "                x_batch = []\n",
    "                end = min(start + batch_size, len(ids_test_split))\n",
    "                ids_test_split_batch = ids_test_split[start:end]\n",
    "                for id in ids_test_split_batch.values:\n",
    "                    img = cv2.imread(weg+'test/{}.jpg'.format(id))\n",
    "                    img = cv2.resize(img, (input_size, input_size_2))\n",
    "                    x_batch.append(img)\n",
    "                x_batch = np.array(x_batch, np.float32) / 255\n",
    "                yield x_batch\n",
    "\n",
    "\n",
    "    print(\"Predicting on {} samples (split {}/{})\".format(len(ids_test_split), split_count, test_splits))\n",
    "    preds = model.predict_generator(generator=test_generator(),\n",
    "                                    steps=np.ceil(float(len(ids_test_split)) / float(batch_size)))\n",
    "    preds = np.squeeze(preds, axis=3)\n",
    "\n",
    "    print(\"Generating masks...\")\n",
    "    for pred in tqdm(preds, miniters=1000):\n",
    "        prob = cv2.resize(pred, (orig_width, orig_height))\n",
    "        mask = prob > threshold\n",
    "        rle = _mask_to_rle_string(mask)\n",
    "        rles.append(rle)\n",
    "\n",
    "print(\"Generating submission file...\")\n",
    "df = pd.DataFrame({'img': names, 'rle_mask': rles})\n",
    "df.to_csv('submit/3_fold_1280_1280_RElU_renorm_04thre.csv.gz', index=False, compression='gzip')\n",
    "print 'finished'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
