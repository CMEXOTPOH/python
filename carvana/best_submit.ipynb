{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "weg = '/media/n01z3/storage3/dataset/carvana/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from renorm import BatchRenormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "white = False\n",
    "image_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    zca_whitening=white)\n",
    "\n",
    "mask_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    zca_whitening=white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_img = lambda im: cv2.imread(join(weg+'train', '{}.jpg'.format(im)))\n",
    "load_mask = lambda im: imread(join(weg+'train_masks', '{}_mask.gif'.format(im)))\n",
    "load_mask_gif = lambda im: imread(join(weg+'train_masks', '{}_mask.gif'.format(im)))[:,:,0]\n",
    "\n",
    "resize = lambda im: downscale_local_mean(im, (4,4) if im.ndim==2 else (4,4,1))\n",
    "mask_image = lambda im, mask: (im * np.expand_dims(mask, 2))\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_gen(size=1,height=160,width=240,aug=True,inter=True,fit=False):\n",
    "    counter = 0 #счетчик запускам\n",
    "    global fold_number\n",
    "    select = df_folds.img.values[df_folds.fold!=fold_number]\n",
    "    number_of_batches = np.ceil(len(select)/size) #количестов партий - зависит от размера партии\n",
    "    while 1:\n",
    "\n",
    "\n",
    "\n",
    "        cc = 0\n",
    "        x = np.empty((size, height, width, 3), dtype=np.float32) # пустой массив для загрузки картинок\n",
    "        y = np.empty((size, height, width, 1), dtype=np.float32)\n",
    "        for img_id in select[size*counter:size*(counter+1)]: #16\n",
    "\n",
    "            imgs_id = [cv2.resize(load_img(img_id),(width,height))/255.]\n",
    "            # Input is image + mean image per channel + std image per channel\n",
    "           \n",
    "            mask_16 = [cv2.resize(load_mask(img_id), ( width,height))/ 255.]\n",
    "            try:\n",
    "                if mask_16[0].shape[2]>1:\n",
    "\n",
    "                    mask_16 = [cv2.resize(load_mask_gif(img_id), ( width,height))/ 255.]\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            #X[i] = np.concatenate([imgs_id[idx-1], np.mean(imgs_id, axis=0), np.std(imgs_id, axis=0)], axis=2)\n",
    "            \n",
    "            x[cc:(1+cc)] = np.array(imgs_id)\n",
    "            y[cc:(1+cc)] = np.expand_dims(np.array(mask_16),3)\n",
    "            \n",
    "            cc+=1    \n",
    "        del imgs_id\n",
    "        counter+=1\n",
    "        SEED = int(np.random.randint(0,999999,1))\n",
    "        if inter == False: #если не чередуем данные\n",
    "            if aug == True:  # делаем ли аугментацию?\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "\n",
    "\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "\n",
    "            if aug == False: # или базовую картинку?\n",
    "                yield(x,y)\n",
    "\n",
    "        if inter == True: # если чередуем то по очереди загружаем то одно то другое\n",
    "            if counter % 2 ==0:\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "\n",
    "            else:\n",
    "                yield(x,y)\n",
    "                \n",
    "        if counter == number_of_batches:\n",
    "            counter = 0\n",
    "            np.random.shuffle(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_gen(size=1,height=160,width=240,aug=True,inter = True,fit=False):\n",
    "    global fold_number\n",
    "    select = df_folds.img.values[df_folds.fold==fold_number]\n",
    "    number_of_batches = np.ceil(len(select)/size) #количестов партий - зависит от размера партии\n",
    "    counter = 0\n",
    "    while 1:\n",
    "\n",
    "\n",
    "\n",
    "        cc = 0\n",
    "        x = np.empty((size, height, width, 3), dtype=np.float32) # пустой массив для загрузки картинок\n",
    "        y = np.empty((size, height, width, 1), dtype=np.float32)\n",
    "        for img_id in select[size*counter:size*(counter+1)]: #16\n",
    "\n",
    "            imgs_id = [cv2.resize(load_img(img_id),(width,height))/255.]\n",
    "            # Input is image + mean image per channel + std image per channel\n",
    "            mask_16 = [cv2.resize(load_mask(img_id), ( width,height))/ 255.]\n",
    "            try:\n",
    "                if mask_16[0].shape[2]>1:\n",
    "\n",
    "                    mask_16 = [cv2.resize(load_mask_gif(img_id), ( width,height))/ 255.]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            x[cc:(1+cc)] = np.array(imgs_id)\n",
    "            y[cc:(1+cc)] = np.expand_dims(np.array(mask_16),3)\n",
    "            \n",
    "            cc+=1    \n",
    "        del imgs_id\n",
    "        counter+=1\n",
    "        \n",
    "        SEED = int(np.random.randint(0,999999,1))\n",
    "        if inter == False: #если не чередуем данные\n",
    "            if aug == True:  # делаем ли аугментацию?\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "\n",
    "\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "                #del img,msk\n",
    "                #del x,y\n",
    "            if aug == False: # или базовую картинку?\n",
    "                yield(x,y)\n",
    "                #del x,y\n",
    "        if inter == True: # если чередуем то по очереди загружаем то одно то другое\n",
    "            if counter % 2 ==0:\n",
    "                if fit==True:\n",
    "                    image_generator.fit(x)\n",
    "                    mask_generator.fit(y)\n",
    "                for img in image_generator.flow((x),batch_size=size,seed=SEED):\n",
    "                    break\n",
    "                \n",
    "                for msk in mask_generator.flow((y),batch_size=size,seed=SEED):\n",
    "                    break \n",
    "                yield(img,msk)\n",
    "                #del img,msk\n",
    "                #del x,y\n",
    "            else:\n",
    "                yield(x,y)\n",
    "                #del x,y\n",
    "        \n",
    "        if counter == number_of_batches:\n",
    "            counter = 0\n",
    "            np.random.shuffle(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, BatchNormalization, Activation, UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_unet_1024(input_shape=(1280, 1280, 3),\n",
    "                 num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 512\n",
    "\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(inputs)\n",
    "    down0a = BatchRenormalization()(down0a)\n",
    "    down0a = ELU()(down0a)\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(down0a)\n",
    "    down0a = BatchRenormalization()(down0a)\n",
    "    down0a = ELU()(down0a)\n",
    "    down0a_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0a)\n",
    "    # 256\n",
    "\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0a_pool)\n",
    "    down0 = BatchRenormalization()(down0)\n",
    "    down0 = ELU()(down0)\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchRenormalization()(down0)\n",
    "    down0 = ELU()(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchRenormalization()(down1)\n",
    "    down1 = ELU()(down1)\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchRenormalization()(down1)\n",
    "    down1 = ELU()(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchRenormalization()(down2)\n",
    "    down2 = ELU()(down2)\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchRenormalization()(down2)\n",
    "    down2 = ELU()(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchRenormalization()(down3)\n",
    "    down3 = ELU()(down3)\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchRenormalization()(down3)\n",
    "    down3 = ELU()(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "    # 16\n",
    "\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n",
    "    down4 = BatchRenormalization()(down4)\n",
    "    down4 = ELU()(down4)\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n",
    "    down4 = BatchRenormalization()(down4)\n",
    "    down4 = ELU()(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "    # 8\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n",
    "    center = BatchRenormalization()(center)\n",
    "    center = ELU()(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchRenormalization()(center)\n",
    "    center = ELU()(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down4, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchRenormalization()(up4)\n",
    "    up4 = ELU()(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down3, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchRenormalization()(up3)\n",
    "    up3 = ELU()(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchRenormalization()(up2)\n",
    "    up2 = ELU()(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchRenormalization()(up1)\n",
    "    up1 = ELU()(up1)\n",
    "    # 128\n",
    "\n",
    "    up0 = UpSampling2D((2, 2))(up1)\n",
    "    up0 = concatenate([down0, up0], axis=3)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchRenormalization()(up0)\n",
    "    up0 = ELU()(up0)\n",
    "    # 256\n",
    "\n",
    "    up0a = UpSampling2D((2, 2))(up0)\n",
    "    up0a = concatenate([down0a, up0a], axis=3)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchRenormalization()(up0a)\n",
    "    up0a = ELU()(up0a)\n",
    "    # 512\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up0a)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss=dice_coef_loss, metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_loss,'accuracy'])\n",
    "    #model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='binary_crossentropy', metrics=[dice_loss,'accuracy'])\n",
    "    #SGD(lr=0.01, momentum=0.9)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_unet_1024()\n",
    "model.load_weights('unet_new_1280_1280_2_batch_renorm_9_my_gen_ELU.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "df_folds = pd.read_csv(weg+'folds_ready.csv')\n",
    "df_train = pd.read_csv(weg+'train_masks.csv')\n",
    "ids_train = df_train['img'].map(lambda s: s.split('.')[0])\n",
    "\n",
    "input_size_1 = 1920\n",
    "input_size_2 = 1280\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "\n",
    "#ids_train_split, ids_valid_split = train_test_split(ids_train, test_size=0.1)#, random_state=42)\n",
    "\n",
    "#print('Training on {} samples'.format(len(ids_train_split)))\n",
    "#print('Validating on {} samples'.format(len(ids_valid_split)))\n",
    "\n",
    "\n",
    "def randomShiftScaleRotate(image, mask,\n",
    "                           shift_limit=(-0.0625, 0.0625),\n",
    "                           scale_limit=(-0.1, 0.1),\n",
    "                           rotate_limit=(-45, 45), aspect_limit=(0, 0),\n",
    "                           borderMode=cv2.BORDER_CONSTANT, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        height, width, channel = image.shape\n",
    "\n",
    "        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree\n",
    "        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "        sx = scale * aspect / (aspect ** 0.5)\n",
    "        sy = scale / (aspect ** 0.5)\n",
    "        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
    "        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
    "\n",
    "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "        box1 = box0 - np.array([width / 2, height / 2])\n",
    "        box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "        box0 = box0.astype(np.float32)\n",
    "        box1 = box1.astype(np.float32)\n",
    "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "        image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                    borderValue=(\n",
    "                                        0, 0,\n",
    "                                        0,))\n",
    "        mask = cv2.warpPerspective(mask, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                   borderValue=(\n",
    "                                       0, 0,\n",
    "                                       0,))\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def randomHorizontalFlip(image, mask, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def train_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(ids_train_split), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(ids_train_split))\n",
    "            ids_train_batch = ids_train_split[start:end]\n",
    "            for id in ids_train_batch.values:\n",
    "                img = cv2.imread(weg+'train/{}.jpg'.format(id))\n",
    "                img = cv2.resize(img, (input_size_1, input_size_2))\n",
    "                mask = imread(weg+'train_masks/{}_mask.gif'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "                try:\n",
    "                    if mask.shape[2]>1:\n",
    "\n",
    "                        mask = mask[:,:,0]\n",
    "                except:\n",
    "                    pass\n",
    "                mask = cv2.resize(mask, (input_size_1, input_size_2))\n",
    "                img, mask = randomShiftScaleRotate(img, mask,\n",
    "                                                   shift_limit=(-0.0625, 0.0625),\n",
    "                                                   scale_limit=(-0.1, 0.1),\n",
    "                                                   rotate_limit=(-0, 0))\n",
    "                img, mask = randomHorizontalFlip(img, mask)\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "\n",
    "def valid_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(ids_valid_split), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(ids_valid_split))\n",
    "            ids_valid_batch = ids_valid_split[start:end]\n",
    "            for id in ids_valid_batch.values:\n",
    "                img = cv2.imread(weg+'train/{}.jpg'.format(id))\n",
    "                img = cv2.resize(img, (input_size_1, input_size_2))\n",
    "                mask = imread(weg+'train_masks/{}_mask.gif'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "                try:\n",
    "                    if mask.shape[2]>1:\n",
    "\n",
    "                        mask = mask[:,:,0]\n",
    "                except:\n",
    "                    pass\n",
    "                mask = cv2.resize(mask, (input_size_1, input_size_2))\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tqdm import tqdm\n",
    "size_1 = 1280\n",
    "size_2 = 1280\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df_test = pd.read_csv(weg+'sample_submission.csv')\n",
    "ids_test = df_test['img'].map(lambda s: s.split('.')[0])\n",
    "for fold in [2,3]:\n",
    "    print 'FOLD ' + str(fold)\n",
    "    model = get_unet_1024()\n",
    "    model.load_weights(str(fold)+'_fold_1280_1280_ElU_renorm.hdf5')\n",
    "    for test_id in tqdm(ids_test.values,miniters=1000):\n",
    "        if not os.path.exists(weg+str(fold)+'_fold_test_predicted'): os.mkdir(weg+str(fold)+'_fold_test_predicted')\n",
    "        test_img =  cv2.resize(cv2.imread(weg+'test/{}.jpg'.format(test_id)),(size_1,size_2))/255.\n",
    "        test_img = np.expand_dims(test_img,0)\n",
    "        pred = model.predict(test_img)[0]\n",
    "        np.savez(weg+str(fold)+'_fold_test_predicted/' + test_id,pred)\n",
    "    print 'Saved for fold '+ str(fold)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 66937/100064 [12:38:37<7:05:05,  1.30it/s] "
     ]
    }
   ],
   "source": [
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    import cv2\n",
    "    from tqdm import tqdm\n",
    "    threshold = 0.5\n",
    "\n",
    "\n",
    "    \n",
    "    df_test = pd.read_csv(weg+'sample_submission.csv')\n",
    "    ids_test = df_test['img'].map(lambda s: s.split('.')[0])\n",
    "\n",
    "\n",
    "    orig_width = 1918\n",
    "    orig_height = 1280\n",
    "\n",
    "    def _mask_to_rle_string(mask):\n",
    "        \"\"\"Convert boolean/`binary uint` mask to RLE string.\"\"\"\n",
    "        # Mask to RLE\n",
    "        pixels = mask.flatten()\n",
    "        pixels[0] = 0\n",
    "        pixels[-1] = 0\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "        runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "\n",
    "        # RLE to string\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "\n",
    "    names = []\n",
    "    for id in ids_test:\n",
    "        names.append('{}.jpg'.format(id))\n",
    "\n",
    "\n",
    "    rles = []\n",
    "\n",
    "    for id_1 in tqdm(ids_test,miniters=1000):\n",
    "                \n",
    "\n",
    "        x0 = np.load(weg+str(0)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.15\n",
    "        x1 = np.load(weg+str(1)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.05\n",
    "        x2 = np.load(weg+str(2)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.15\n",
    "        x3 = np.load(weg+str(3)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.1\n",
    "        x4 = np.load(weg+str(4)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.22\n",
    "        \n",
    "        img = cv2.imread(weg+'test/{}.jpg'.format(id_1))\n",
    "        img = cv2.resize(img, (x0.shape[0], x0.shape[1]))\n",
    "        img = img/255.\n",
    "        img = np.expand_dims(img,0)\n",
    "        img = model.predict(img)\n",
    "        img = img[0] *0.33       \n",
    "        if not os.path.exists(weg+'best_submission'): os.mkdir(weg+'best_submission')    \n",
    "        \n",
    "        loaded = x0+x1+x2+x3+x4+img\n",
    "        np.savez_compressed(weg+'best_submission/' + id_1,loaded)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(weg+'sample_submission.csv')\n",
    "ids_test = df_test['img'].map(lambda s: s.split('.')[0])\n",
    "for fold in [0,1]:\n",
    "    print ('FOLD ' + str(fold))\n",
    "    model = get_unet_1024()\n",
    "    model.load_weights(str(fold)+'_fold_1280_1280_ElU_renorm.hdf5')\n",
    "    for test_id in tqdm(ids_test.values,miniters=1000):\n",
    "        if not os.path.exists(weg+'best_submission'): os.mkdir(weg+'best_submission')\n",
    "        test_img =  cv2.resize(cv2.imread(weg+'test/{}.jpg'.format(test_id)),(size_1,size_2))/255.\n",
    "        test_img = np.expand_dims(test_img,0)\n",
    "        pred = model.predict(test_img)[0]\n",
    "        np.savez_compressed(weg+str(fold)+'_fold_test_predicted/' + test_id,pred)\n",
    "    print ('Saved for fold '+ str(fold))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = img[0] *0.33         \n",
    "x0 = np.load(weg+str(0)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.15         \n",
    "x1 = np.load(weg+str(1)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.05         \n",
    "x2 = np.load(weg+str(2)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.15         \n",
    "x3 = np.load(weg+str(3)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.1         \n",
    "x4 = np.load(weg+str(4)+'_fold_test_predicted/' + str(id_1)+'.npz')['arr_0']*0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c84473ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(loaded))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
