{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "(0, 5.19060891866684)\n",
      "(1, 3.2204023897647858)\n",
      "(2, 3.4212912917137146)\n",
      "(3, 3.0026599019765854)\n",
      "(4, 2.3899604082107544)\n",
      "(5, 2.1484271734952927)\n",
      "(6, 2.322308212518692)\n",
      "(7, 2.013039618730545)\n",
      "(8, 1.7451282441616058)\n",
      "(9, 1.6573316752910614)\n",
      "(10, 1.4080515429377556)\n",
      "(11, 1.4164350628852844)\n",
      "(12, 1.3474266156554222)\n",
      "(13, 1.156446523964405)\n",
      "(14, 1.1278898790478706)\n",
      "(15, 1.1043170019984245)\n",
      "(16, 0.9991574510931969)\n",
      "(17, 0.9785415977239609)\n",
      "(18, 0.8855770379304886)\n",
      "(19, 0.8161162585020065)\n",
      "(20, 0.8468064442276955)\n",
      "(21, 0.7921069264411926)\n",
      "(22, 0.7489682510495186)\n",
      "(23, 0.689446147531271)\n",
      "(24, 0.6908483579754829)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as fn\n",
    "\n",
    "import dlc_practical_prologue as prologue\n",
    " \n",
    "\n",
    "train_input, train_target, test_input, test_target = prologue.load_data(vectorize_labels = True, normalize = True, flatten = False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fn.relu(fn.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = fn.relu(fn.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = fn.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    def predict(self,input_):\n",
    "        return self.forward(input_)\n",
    "    \n",
    "    #train model(model, train input, train target, mini batch size)\n",
    "train_input, train_target, test_input, test_target = prologue.load_data(vectorize_labels = True, normalize = True, flatten = False)\n",
    "\n",
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "\n",
    "model, criterion = Net(), nn.MSELoss()\n",
    "eta, mini_batch_size = 1e-1, 100\n",
    "\n",
    "for e in range(0, 25):\n",
    "    sum_loss = 0\n",
    "    # We do this with mini-batches\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):\n",
    "        output = model.forward(train_input.narrow(0, b, mini_batch_size))\n",
    "        loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "        sum_loss = sum_loss + loss.data[0]\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in model.parameters():\n",
    "            p.data.sub_(eta * p.grad.data)\n",
    "    print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДЗ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "(0, 6.149405300617218)\n",
      "(1, 4.11646956205368)\n",
      "(2, 3.513435810804367)\n",
      "(3, 3.178410291671753)\n",
      "(4, 2.712064817547798)\n",
      "(5, 2.593950167298317)\n",
      "(6, 2.346210092306137)\n",
      "(7, 2.2079054415225983)\n",
      "(8, 1.999129593372345)\n",
      "(9, 1.7727029919624329)\n",
      "(10, 1.814366027712822)\n",
      "(11, 1.5671112537384033)\n",
      "(12, 1.5435365289449692)\n",
      "(13, 1.3395438119769096)\n",
      "(14, 1.2860185727477074)\n",
      "(15, 1.206365428864956)\n",
      "(16, 1.113737240433693)\n",
      "(17, 1.0559347197413445)\n",
      "(18, 1.0365790575742722)\n",
      "(19, 1.0097511634230614)\n",
      "(20, 0.9540660157799721)\n",
      "(21, 0.8689780756831169)\n",
      "(22, 0.8584974408149719)\n",
      "(23, 0.8329798355698586)\n",
      "(24, 0.7821511253714561)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.8514 -0.7225 -1.0671  ...  -1.0550 -1.2438  0.3509\n",
       "-0.8843 -1.0108 -0.9049  ...  -1.0049 -1.1757 -1.0191\n",
       " 0.7224 -0.9229 -1.0133  ...  -0.9596 -1.3161 -0.9705\n",
       "          ...             ⋱             ...          \n",
       " 0.5724 -0.8131 -0.6505  ...  -0.9395 -1.3379 -0.7828\n",
       "-0.2353 -0.9174 -0.5348  ...  -0.9878 -1.1365 -0.8408\n",
       "-1.1246 -0.9925 -0.7735  ...  -0.9870 -1.3273 -1.0073\n",
       "[torch.FloatTensor of size 100x10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    eta = 1e-1\n",
    "    criterion = nn.MSELoss()\n",
    "    for e in range(0, 25):\n",
    "        sum_loss = 0\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model.forward(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss = sum_loss + loss.data[0]\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta * p.grad.data)\n",
    "        print(e, sum_loss)\n",
    "    return output\n",
    "mini_batch_size = 100\n",
    "model = Net()\n",
    "train_input, train_target, test_input, test_target = prologue.load_data(vectorize_labels = True, normalize = True, flatten = False)\n",
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "\n",
    "train_model(model,train_input,train_target,mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 5, 5])\n",
      "torch.Size([32, 1, 5, 5])\n",
      "<built-in method sub_ of torch.FloatTensor object at 0x7f15e6876dd0>\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "<built-in method sub_ of torch.FloatTensor object at 0x7f15e6876f38>\n",
      "torch.Size([64, 32, 5, 5])\n",
      "torch.Size([64, 32, 5, 5])\n",
      "<built-in method sub_ of torch.FloatTensor object at 0x7f15e6876f80>\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "<built-in method sub_ of torch.FloatTensor object at 0x7f1596109bd8>\n",
      "torch.Size([200, 256])\n",
      "torch.Size([200, 256])\n",
      "<built-in method sub_ of torch.FloatTensor object at 0x7f15e68483b0>\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "<built-in method sub_ of torch.FloatTensor object at 0x7f15e6848440>\n",
      "torch.Size([10, 200])\n",
      "torch.Size([10, 200])\n",
      "<built-in method sub_ of torch.FloatTensor object at 0x7f15e6848518>\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "<built-in method sub_ of torch.FloatTensor object at 0x7f15e6848638>\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print p.size()\n",
    "    print p.grad.data.size()\n",
    "    print p.data.sub_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "for b in range(0, train_input.size(0), mini_batch_size):\n",
    "    print b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def search(A,value):\n",
    "    global __search__length__\n",
    "    try:\n",
    "        __search__length__\n",
    "    except:\n",
    "        __search__length__ = 0\n",
    "    if value == A[len(A)/2]:\n",
    "        result = len(A)/2+__search__length__\n",
    "        del __search__length__\n",
    "        return result\n",
    "    elif value> A[len(A)/2] and len(A)>1:\n",
    "        __search__length__+=len(A)/2\n",
    "        return search(A[len(A)/2:],value)\n",
    "    elif value< A[len(A)/2] and len(A)>1:\n",
    "        return search(A[:len(A)/2],value)\n",
    "    elif len(A) ==1 and value != A[len(A)/2]:\n",
    "        result = \"None\"\n",
    "        return result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "noise = []\n",
    "for i in xrange(10000):\n",
    "    noise.append(np.random.randn())\n",
    "noise.sort()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test =[]\n",
    "for example in noise:\n",
    "    test.append(noise[search(noise,example)]  - example)\n",
    "print np.sum(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1:1, 2:2, 3:3}\n",
    ">>> dict((key,value) for key, value in a.iteritems() if key == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(u'conflicts', u'february'): 25, (u'conflicts', u'january'): 25}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((key,value) for key, value in test.iteritems() if 'conflicts' in key[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function iteritems>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {(u'conflicts', u'january'): 25,\n",
    "         (u'2008', u'reemerged'): 1,\n",
    "         (u'abandoning', u\"tolstoy's\"): 1,\n",
    "         (u'18', u'charters'): 1,\n",
    "         (u'stirner', u'your'): 1,\n",
    "         (u'execution', u'owing'): 1,\n",
    "         (u'dictadura', u'rosso'): 1,\n",
    "         (u'fotlu', u'netherlands'): 1,\n",
    "         (u'majority', u'specific'): 1,\n",
    "         (u'collectivise', u'liberate'): 1,\n",
    "       (u'january', u'conflicts'): 1,\n",
    "       (u'conflicts', u'february'): 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'conflicts', u'january'), (u'conflicts', u'february')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(lambda x: 'conflicts' in x[0], test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07492116"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.03615831 + 0.03876285"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
